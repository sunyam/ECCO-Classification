{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating feature vectors for the files that I've to label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename          97688\n",
      "DocumentID        97688\n",
      "ESTC_ID           87270\n",
      "Date                131\n",
      "Title             81957\n",
      "Vol_Number          146\n",
      "Author            18892\n",
      "Imprint           69271\n",
      "Field_Headings    41218\n",
      "TableName             8\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>ESTC_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Vol_Number</th>\n",
       "      <th>Author</th>\n",
       "      <th>Imprint</th>\n",
       "      <th>Field_Headings</th>\n",
       "      <th>TableName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031300100.xml</td>\n",
       "      <td>31300100</td>\n",
       "      <td>T021625</td>\n",
       "      <td>1736</td>\n",
       "      <td>Bibliotheca topographica Anglicana: or, a new ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Worrall, John</td>\n",
       "      <td>London : printed for J. Worrall at the Dove in...</td>\n",
       "      <td>Books, Prices, Catalogs, Booksellers', Great B...</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0031300200.xml</td>\n",
       "      <td>31300200</td>\n",
       "      <td>T013049</td>\n",
       "      <td>1787</td>\n",
       "      <td>A catalogue of books printed for, and sold by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dilly, Charles</td>\n",
       "      <td>[London], s.n, 1787.</td>\n",
       "      <td>Catalogs, Booksellers', Early works to 1800</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0031300300.xml</td>\n",
       "      <td>31300300</td>\n",
       "      <td>T057382</td>\n",
       "      <td>1800</td>\n",
       "      <td>Rules of a reading-society, established April ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anon</td>\n",
       "      <td>London : printed by H.D. Steel, No. 51, Lothbu...</td>\n",
       "      <td>[London Reading Society], Rules and practice, ...</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0031300400.xml</td>\n",
       "      <td>31300400</td>\n",
       "      <td>T012488</td>\n",
       "      <td>1787</td>\n",
       "      <td>Rules for regulating the subscription library ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anon</td>\n",
       "      <td>Stamford : printed by Newcomb and Peat, [1787].</td>\n",
       "      <td>[Stamford Subscription Library], Rules and pra...</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0031300500.xml</td>\n",
       "      <td>31300500</td>\n",
       "      <td>W029739</td>\n",
       "      <td>1773</td>\n",
       "      <td>A catalogue of books, imported and to be sold ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Knox, Henry</td>\n",
       "      <td>[Boston : Sold by Henry Knox, 1773].</td>\n",
       "      <td>Booksellers and bookselling, Massachusetts, Bo...</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filename  DocumentID  ESTC_ID  Date  \\\n",
       "0  0031300100.xml    31300100  T021625  1736   \n",
       "1  0031300200.xml    31300200  T013049  1787   \n",
       "2  0031300300.xml    31300300  T057382  1800   \n",
       "3  0031300400.xml    31300400  T012488  1787   \n",
       "4  0031300500.xml    31300500  W029739  1773   \n",
       "\n",
       "                                               Title Vol_Number  \\\n",
       "0  Bibliotheca topographica Anglicana: or, a new ...          0   \n",
       "1  A catalogue of books printed for, and sold by ...          0   \n",
       "2  Rules of a reading-society, established April ...          0   \n",
       "3  Rules for regulating the subscription library ...          0   \n",
       "4  A catalogue of books, imported and to be sold ...          0   \n",
       "\n",
       "           Author                                            Imprint  \\\n",
       "0   Worrall, John  London : printed for J. Worrall at the Dove in...   \n",
       "1  Dilly, Charles                               [London], s.n, 1787.   \n",
       "2            Anon  London : printed by H.D. Steel, No. 51, Lothbu...   \n",
       "3            Anon    Stamford : printed by Newcomb and Peat, [1787].   \n",
       "4     Knox, Henry               [Boston : Sold by Henry Knox, 1773].   \n",
       "\n",
       "                                      Field_Headings        TableName  \n",
       "0  Books, Prices, Catalogs, Booksellers', Great B...  Manifest_GenRef  \n",
       "1        Catalogs, Booksellers', Early works to 1800  Manifest_GenRef  \n",
       "2  [London Reading Society], Rules and practice, ...  Manifest_GenRef  \n",
       "3  [Stamford Subscription Library], Rules and pra...  Manifest_GenRef  \n",
       "4  Booksellers and bookselling, Massachusetts, Bo...  Manifest_GenRef  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "to_label = pd.read_csv('./fnames_to_label.csv')\n",
    "print(to_label.nunique())\n",
    "to_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>TableName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031300100.xml</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0031300200.xml</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0031300300.xml</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0031300400.xml</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0031300500.xml</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filename        TableName\n",
       "0  0031300100.xml  Manifest_GenRef\n",
       "1  0031300200.xml  Manifest_GenRef\n",
       "2  0031300300.xml  Manifest_GenRef\n",
       "3  0031300400.xml  Manifest_GenRef\n",
       "4  0031300500.xml  Manifest_GenRef"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_label[['Filename', 'TableName']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Manifest_GenRef',\n",
       " 'Manifest_HistAndGeo',\n",
       " 'Manifest_Law',\n",
       " 'Manifest_LitAndLang1',\n",
       " 'Manifest_LitAndLang2',\n",
       " 'Manifest_MedSciTech',\n",
       " 'Manifest_RelandPhil',\n",
       " 'Manifest_SSAndFineArt'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['TableName'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2: All words > len(3)\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "\n",
    "'''\n",
    "Takes in a list of sentences where each sentence is a list of words, and optional argument 'user_stopwords'.\n",
    "Returns a dictionary with each 'word' is the key, and 'count' as the value.\n",
    "'''\n",
    "def calculate_frequencies(sentences_ll, user_stopwords=None):  # sentences_ll is a list of lists\n",
    "    frequency = defaultdict(int)    # default value : 0\n",
    "    \n",
    "    for sentence in sentences_ll:\n",
    "        for word in sentence:\n",
    "            word = word.lower()\n",
    "            \n",
    "            if len(word) > 3:\n",
    "                frequency[word] += 1\n",
    "\n",
    "    return frequency\n",
    "\n",
    "'''\n",
    "Takes in text, and n = number of features\n",
    "Returns a list of n most frequent words\n",
    "'''\n",
    "def get_features(text, n, user_stopwords=None):  # n is the desired no. of features\n",
    "    sentences = sent_tokenize(text.decode('utf8'))\n",
    "    \n",
    "    sentences_ll = []\n",
    "    for s in sentences:\n",
    "        words = word_tokenize(s)\n",
    "        sentences_ll.append(words)\n",
    "\n",
    "    frequency = calculate_frequencies(sentences_ll, user_stopwords)\n",
    "    return nlargest(n, frequency, key=frequency.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0031300100.xml', 'Manifest_GenRef'), ('0031300200.xml', 'Manifest_GenRef'), ('0031300300.xml', 'Manifest_GenRef'), ('0031300400.xml', 'Manifest_GenRef')]\n"
     ]
    }
   ],
   "source": [
    "tuples = [tuple(x) for x in df.values]\n",
    "print(tuples[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# Read files from Dataset\n",
    "path = './FINAL_Dataset/'\n",
    "\n",
    "map_filename_to_1000words = {}\n",
    "\n",
    "counter = 0\n",
    "for (fname, folder) in tuples[:100]:\n",
    "    with open(path+folder+'/'+fname+'.txt', 'rb') as f:\n",
    "        map_filename_to_1000words[fname] = get_features(f.read(), 1000)\n",
    "        \n",
    "    if counter % 10 == 0:\n",
    "        print(counter)\n",
    "    counter += 1\n",
    "    \n",
    "# Should stop at 95000\n",
    "# Started running at 3PM Tuesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./features_97k.pickle', 'wb') as f:\n",
    "    pickle.dump(map_filename_to_1000words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0031300100.xml', '0031300200.xml', '0031300300.xml', '0031300400.xml', '0031300500.xml', '0031300600.xml', '0031300700.xml', '0031300800.xml', '0031300900.xml', '0031301000.xml', '0031301100.xml', '0031301200.xml', '0031301300.xml', '0031301400.xml', '0031301500.xml', '0031301700.xml', '0031301800.xml', '0031301900.xml', '0031302000.xml', '0031302100.xml', '0031302200.xml', '0031302300.xml', '0031302400.xml', '0031302500.xml', '0031400101.xml', '0031400102.xml', '0031400103.xml', '0031400104.xml', '0031400105.xml', '0031400106.xml', '0031400107.xml', '0031400108.xml', '0031400200.xml', '0031400300.xml', '0031400400.xml', '0031400500.xml', '0031400600.xml', '0031500100.xml', '0031500200.xml', '0031500300.xml', '0031500400.xml', '0031500500.xml', '0031500600.xml', '0031500700.xml', '0031500800.xml', '0031500900.xml', '0031501000.xml', '0031501100.xml', '0031501200.xml', '0031501300.xml', '0031501400.xml', '0031501500.xml', '0031501600.xml', '0031501700.xml', '0031501800.xml', '0031501900.xml', '0031502000.xml', '0048600100.xml', '0048600200.xml', '0048600300.xml', '0048600400.xml', '0048600500.xml', '0048600600.xml', '0048600700.xml', '0048600800.xml', '0048600900.xml', '0048601000.xml', '0048601100.xml', '0048601200.xml', '0048601300.xml', '0048601400.xml', '0048601500.xml', '0048601600.xml', '0048601700.xml', '0048601800.xml', '0048601900.xml', '0048602000.xml', '0048602100.xml', '0048602200.xml', '0048602300.xml', '0048602400.xml', '0048602500.xml', '0048602600.xml', '0048602700.xml', '0048602800.xml', '0048602900.xml', '0048603000.xml', '0048603100.xml', '0048603200.xml', '0048603300.xml', '0048603400.xml', '0048603500.xml', '0048603600.xml', '0048603700.xml', '0048603800.xml', '0048603900.xml', '0048604000.xml', '0048604100.xml', '0048604200.xml', '0048604300.xml'])\n"
     ]
    }
   ],
   "source": [
    "with open('./features_97k.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
