{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything:  57231\n",
      "Count:  57231\n",
      "Vectorizer:  (57231, 2141835)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load CSVs and getting it ready for CountVectorizer.\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "numberOfFeatures = 1000\n",
    "\n",
    "# categories = ['Agriculture.csv', 'Biography.csv', 'Botany.csv', 'Church.csv', 'Commerce.csv', 'Dictionaries.csv', \n",
    "#               'Drama.csv', 'Fiction.csv', 'History.csv', 'History_Natural.csv', 'Law.csv', 'Mathematics.csv', \n",
    "#               'Medicine.csv', 'Physics.csv', 'Poetry.csv', 'Politics.csv', 'Rhetoric.csv', 'Sermons.csv', \n",
    "#               'Travels.csv']\n",
    "\n",
    "df_agri = pd.read_csv('../DocClass5.0/5_features/Model2_length3/agri_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "\n",
    "df_botany = pd.read_csv('../DocClass5.0/5_features/Model2_length3/botany_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_church = pd.read_csv('../DocClass5.0/5_features/Model2_length3/church_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_commerce = pd.read_csv('../DocClass5.0/5_features/Model2_length3/commerce_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_drama = pd.read_csv('../DocClass5.0/5_features/Model2_length3/drama_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_fiction = pd.read_csv('../DocClass5.0/5_features/Model2_length3/fiction_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_history = pd.read_csv('../DocClass5.0/5_features/Model2_length3/history_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_historyNatural = pd.read_csv('../DocClass5.0/5_features/Model2_length3/historyNatural_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_law = pd.read_csv('../DocClass5.0/5_features/Model2_length3/law_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_math = pd.read_csv('../DocClass5.0/5_features/Model2_length3/math_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_med = pd.read_csv('../DocClass5.0/5_features/Model2_length3/med_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_phy = pd.read_csv('../DocClass5.0/5_features/Model2_length3/phy_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_poetry = pd.read_csv('../DocClass5.0/5_features/Model2_length3/poetry_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_politics = pd.read_csv('../DocClass5.0/5_features/Model2_length3/politics_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_rhetoric = pd.read_csv('../DocClass5.0/5_features/Model2_length3/rhetoric_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_sermons = pd.read_csv('../DocClass5.0/5_features/Model2_length3/sermons_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_travels = pd.read_csv('../DocClass5.0/5_features/Model2_length3/travels_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "\n",
    "# Removing NaN\n",
    "df_agri.fillna('', inplace=True)\n",
    "\n",
    "df_botany.fillna('', inplace=True)\n",
    "df_church.fillna('', inplace=True)\n",
    "df_commerce.fillna('', inplace=True)\n",
    "df_drama.fillna('', inplace=True)\n",
    "df_fiction.fillna('', inplace=True)\n",
    "df_history.fillna('', inplace=True)\n",
    "df_historyNatural.fillna('', inplace=True)\n",
    "df_law.fillna('', inplace=True)\n",
    "df_math.fillna('', inplace=True)\n",
    "df_med.fillna('', inplace=True)\n",
    "df_phy.fillna('', inplace=True)\n",
    "df_poetry.fillna('', inplace=True)\n",
    "df_politics.fillna('', inplace=True)\n",
    "df_rhetoric.fillna('', inplace=True)\n",
    "df_sermons.fillna('', inplace=True)\n",
    "df_travels.fillna('', inplace=True)\n",
    "\n",
    "# Changing it to CountVec fashion:\n",
    "agri = [' '.join(str(r) for r in row) for row in df_agri.values]\n",
    "\n",
    "botany = [' '.join(str(r) for r in row) for row in df_botany.values]\n",
    "church = [' '.join(str(r) for r in row) for row in df_church.values]\n",
    "commerce = [' '.join(str(r) for r in row) for row in df_commerce.values]\n",
    "\n",
    "drama = [' '.join(str(r) for r in row) for row in df_drama.values]\n",
    "fiction = [' '.join(str(r) for r in row) for row in df_fiction.values]\n",
    "history = [' '.join(str(r) for r in row) for row in df_history.values]\n",
    "historyNatural = [' '.join(str(r) for r in row) for row in df_historyNatural.values]\n",
    "law = [' '.join(str(r) for r in row) for row in df_law.values]\n",
    "math = [' '.join(str(r) for r in row) for row in df_math.values]\n",
    "med = [' '.join(str(r) for r in row) for row in df_med.values]\n",
    "\n",
    "phy = [' '.join(str(r) for r in row) for row in df_phy.values]\n",
    "poetry = [' '.join(str(r) for r in row) for row in df_poetry.values]\n",
    "politics = [' '.join(str(r) for r in row) for row in df_politics.values]\n",
    "rhetoric = [' '.join(str(r) for r in row) for row in df_rhetoric.values]\n",
    "sermons = [' '.join(str(r) for r in row) for row in df_sermons.values]\n",
    "travels = [' '.join(str(r) for r in row) for row in df_travels.values]\n",
    "\n",
    "# Passing it to CountVectorizer:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "everything = agri + botany + church + commerce + drama + fiction + history + historyNatural + law + math + med + \\\n",
    "             phy + poetry + politics + rhetoric + sermons + travels\n",
    "print(\"Everything: \", len(everything))\n",
    "\n",
    "# Defining labels (must be in the same order)\n",
    "labels = len(agri)*['Agriculture'] + len(botany)*['Botany'] + len(church)*['Church'] + len(commerce)*['Commerce'] + len(drama)*['Drama'] + len(fiction)*['Fiction'] + len(history)*['History'] + len(historyNatural)*['History Natural'] + len(law)*['Law'] + len(math)*['Mathematics'] + len(med)*['Medicine'] + len(phy)*['Physics'] + len(poetry)*['Poetry'] + len(politics)*['Politics'] + len(rhetoric)*['Rhetoric'] + len(sermons)*['Sermons'] + len(travels)*['Travels']\n",
    "\n",
    "# Storing sizes (in same order)\n",
    "sizes_in_same_order = [len(agri), len(botany), len(church), len(commerce), len(drama), len(fiction), len(history), len(historyNatural), len(law), len(math), len(med), len(phy), len(poetry), len(politics), len(rhetoric), len(sermons), len(travels)]\n",
    "\n",
    "count = 0\n",
    "for i in sizes_in_same_order:\n",
    "    count += i\n",
    "print(\"Count: \", count)\n",
    "\n",
    "vectorizer500 = CountVectorizer()\n",
    "X500 = vectorizer500.fit_transform(everything)\n",
    "print(\"Vectorizer: \", X500.shape) # Prints (57231, something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57231, 2141835)\n",
      "57231\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "# Training SVM on all 57k data\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=5.0)\n",
    "\n",
    "print(X500.shape)\n",
    "print(len(labels))\n",
    "svm.fit(X500, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97688\n"
     ]
    }
   ],
   "source": [
    "# Predicting on 97k files:\n",
    "import pickle\n",
    "with open('./features_97k.pickle', 'rb') as f:\n",
    "    test_features = pickle.load(f)\n",
    "print(len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97688\n",
      "97688\n"
     ]
    }
   ],
   "source": [
    "# Convert test_features dict into two lists (preserving order):\n",
    "\n",
    "fnames = []\n",
    "wordLists = []\n",
    "\n",
    "for (filename, wordList) in test_features.items():\n",
    "    fnames.append(filename)\n",
    "    wordLists.append(wordList)\n",
    "    \n",
    "print(len(fnames))\n",
    "print(len(wordLists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0129500100.xml\n",
      "['with', 'when', 'phantom', 'that', 'will', 'what', 'have', 'their', 'more', 'kind', 'these', 'from', 'vain', 'dead', 'know', 'which', 'then', 'days', 'haunts', 'would', 'night', 'looks', 'some', 'thus', 'something', 'fear', 'every', \"ev'ry\", 'fair', 'endless', 'stories', 'been', 'witches', 'phantoms', 'elves', 'play', 'walk', 'witch', 'just', 'reward', 'does', 'miser', 'death', 'breath', 'comes', 'dear', 'behold', 'head', 'seen', 'care', 'sighs', 'cries', 'alas', 'prevail', 'file', 'lonely', 'long', 'gold', 'youth', 'eyes', 'away', 'this', 'dire', 'tale', 'wife', 'spirit', 'wants', 'mind', 'smiles', 'through', 'such', 'inclin', 'they', 'must', 'like', 'form', 'whose', 'various', 'sometimes', 'makes', 'here', 'ever', 'discourse', 'pleasure', 'pain', 'bloom', 'somina', 'vana', 'jacent', 'totidenm', 'quot', 'meffis', 'arijlas', 'silva', 'gerit', 'frondes', 'ejelas', 'littus', 'arenas', 'ovid', 'london', 'printed', 'wfesmninfer', '1935', 'told', 'sprites', 'pranks', 'nights', 'sublime', 'broom-stick', 'rides', 'prudent', 'three-pence', 'hides', 'housewife', 'shoe', 'pinches', 'hard', 'snoring', 'slut', 'whence', 'neat', 'trim', 'hearth', 'found', 'where', 'fairies', 'dance', 'midnight-round', 'dairy-mliaid', 'churn', 'refcntment', 'burn', 'sure', 'once', 'boon', 'wiltces', 'bely', \"gen'rous\", 'after', 'though', 'latelf', 'nightly', 'ill-gotten', 'house', 'husband', 'mourning', 'spouse', 'freth', 'weeds', 'begins', 'league', 'goods', 'brawny', 'teagus', 'reveal', 'hoarded', 'sums', 'other', 'compaflion', 'children', 'shroud', 'muffler', 'hideous', 'sight', 'curtain', 'drawn', 'stand', 'flake', 'wave', 'hand', 'royal', 'dane', 'murther', 'explaimn', 'dejeded', 'dejected', 'bespeak', 'dreadful', 'beware', 'desires', 'heart', 'assail', 'caution', 'pthantom', 'much', 'stands', 'need', 'lffociate', 'relieve', 'fears', 'hours', 'deceive', 'refolv', 'pursues', 'thought', 'morsel', 'brought', 'coquet', 'mistaken', 'maid', 'faithful', 'love', 'femalefalfe', 'lucre', 'fold', 'herself', 'vows', 'broken', 'laid', 'grave', 'constant', 'example', 'injur', 'truth', 'diflurbing', 'dreams', 'couch', 'annoy', 'dying', 'groans', 'peace', 'destroy', 'deep-', 'deep-rooted', 'guilt', 'bofomftains', 'spot', '-the-spot', 'remains', 'tears', 'wifllies', 'might', 'live', 'again', 'repentance', 'late', 'lasting', 'torment', 'fate', 'midnight-spec7re', 'wounds', 'help', 'friends', 'cries.', 'alive', 'thou', 'lhalt', 'mine', 'claim', 'resign', 'roars', 'snatches', 'vengeful', 'fiends', 'future', 'prey', 'confirm', 'print', 'view', 'examples', '-and', '§print', 'true', 'read', 'dismal', 'sleep', \"o'er\", 'goflips', 'bateman', 'loft', 'life', 'jermin', 'came', 'shades', 'below', 'bore', 'swift', 'horrour', \"ihudd'ring\", 'nymphs', 'mischiefs', 'wait', 'thirst', 'ruins', 'groves', 'restless', 'phant.m', 'pensive', 'roves', 'break', 'longs', 'speak', 'grief', 'reft', 'nothing', 'disdainful', 'turns', 'still', 'mual', 'indulge', 'hidden', 'sighing', 'mixes', 'thousand', 'monks', 'contriv', 'yore', 'tradition', 'handed', 'down', 'muse', 'weak', 'fright', 'clown', 'revolving', 'gropes', 'home', \"chris'mnas-a¢\", 'cheat', 'laugh', 'fond', 'conceit', 'spirits', 'judge', 'from-', 'monks-', 'our-selves', 'idle', 'fancies', 'range', 'harmless', 'pos7s', 'doemons', 'change', 'church-yaids', 'parson', 'mare', 'becomes', 'sprite', 'farrer', 'heifer', 'couching', 'made', 'fiend', 'sawicer', 'short', 'ideas', 'reason', 'beaten', 'station', 'gives', 'ground', 'wild', 'imagination', 'bred', 'towns', '-have', 'walks', 'frequent', 'phiantoms', 'lightly', 'swim', 'those', 'grotto', 'skim', 'thoft', 'said', 'name', 'comparison', 'worthy', 'blame', 'simple', 'deceptio', 'share', 'element', 'thence', 'power', 'uate', 'sense', 'compound', 'substantial', 'flejh', 'blood', 'felt', 'undersfood', 'fragrant', 'granted', 'syren', 'ttoice', 'fraught', 'blifi', 'dare', 'clasp', 'nameless', 'charms', 'aerial', 'baulks', 'your', 'arms', 'prays', 'fllines', 'balls', 'plays', 'radiant', 'circles', 'round', 'ring', 'goes', 'court', 'so10', 'masquerade', 'hear', 'evidently', 'fliown', 'inviting', 'known', 'note', 'rules', 'dispense', 'difguis', 'without', 'offence', 'skies', 'cloudless', 'bright', 'zephyrs', 'waft', 'country-air', 'winter', 'noon', 'summer', 'park', 'chief', 'delight', 'thro', 'vis/o', 'glide', 'kindred-phantom', 'side', 'silent', 'hfows', 'disclose', 'tender', 'breast', 'oppreft', \"'till\", 'brave', 'lvlhat', 'atnd', 'scenes', 'valiant', 'knight', 'hath', 'spoke', '-free', 'enchantment', 'broke', 'join', '-disclose', 'treasure', 'otheriwealth', 'surmount', 'arithmetick', 'count', 'leed', 'a-youth', 'childish', 'think', 'attiempt', 'cost', 'phtaatom', 'w..ks', 'relieves', 'talks', 'tyrant', '.custom', 'worse', 'says', \"ne'er\", 'begin', 'question', 'give.an', 'answer', 'conscious', 'bluflies', 'rife', 'sparkle', 'nature', 'deck', 'pride', 'shines', 'freih', 'aukvwards', 'bafhful', \"'swaini\", 'permits', 'rti.l', 'nonelre', 'whper', 'itse', \"hwoi'8loe\", 'e-ly', 'allits.gbeaties', 'rosy', 'fadsa', 'delightful', 'wanton', 'airs', 'foan', 'gie4bp.e', 'wrinkle¢dcates', 'it.willfpai', \"'itbfrom\", 'aimind', 'canker', 'withisfitre', 'mankind', 'each', 'iatil', \"'night\", \"'twill'vexaid\", 'pine', \"whole'ilife\", 'to.tales', 'nfign', 'iphan-toms', 'young', 'misf6otite', 'niever', 'flare', 'soon', 'theyjoy', 'sorrows', 'past', 'beauty', 'last', 'advised', \"e.a'cfibeft\", 'phantodm', 'smile']\n",
      "['with', 'when', 'phantom', 'that', 'will', 'what', 'have', 'their', 'more', 'kind', 'these', 'from', 'vain', 'dead', 'know', 'which', 'then', 'days', 'haunts', 'would', 'night', 'looks', 'some', 'thus', 'something', 'fear', 'every', \"ev'ry\", 'fair', 'endless', 'stories', 'been', 'witches', 'phantoms', 'elves', 'play', 'walk', 'witch', 'just', 'reward', 'does', 'miser', 'death', 'breath', 'comes', 'dear', 'behold', 'head', 'seen', 'care', 'sighs', 'cries', 'alas', 'prevail', 'file', 'lonely', 'long', 'gold', 'youth', 'eyes', 'away', 'this', 'dire', 'tale', 'wife', 'spirit', 'wants', 'mind', 'smiles', 'through', 'such', 'inclin', 'they', 'must', 'like', 'form', 'whose', 'various', 'sometimes', 'makes', 'here', 'ever', 'discourse', 'pleasure', 'pain', 'bloom', 'somina', 'vana', 'jacent', 'totidenm', 'quot', 'meffis', 'arijlas', 'silva', 'gerit', 'frondes', 'ejelas', 'littus', 'arenas', 'ovid', 'london', 'printed', 'wfesmninfer', '1935', 'told', 'sprites', 'pranks', 'nights', 'sublime', 'broom-stick', 'rides', 'prudent', 'three-pence', 'hides', 'housewife', 'shoe', 'pinches', 'hard', 'snoring', 'slut', 'whence', 'neat', 'trim', 'hearth', 'found', 'where', 'fairies', 'dance', 'midnight-round', 'dairy-mliaid', 'churn', 'refcntment', 'burn', 'sure', 'once', 'boon', 'wiltces', 'bely', \"gen'rous\", 'after', 'though', 'latelf', 'nightly', 'ill-gotten', 'house', 'husband', 'mourning', 'spouse', 'freth', 'weeds', 'begins', 'league', 'goods', 'brawny', 'teagus', 'reveal', 'hoarded', 'sums', 'other', 'compaflion', 'children', 'shroud', 'muffler', 'hideous', 'sight', 'curtain', 'drawn', 'stand', 'flake', 'wave', 'hand', 'royal', 'dane', 'murther', 'explaimn', 'dejeded', 'dejected', 'bespeak', 'dreadful', 'beware', 'desires', 'heart', 'assail', 'caution', 'pthantom', 'much', 'stands', 'need', 'lffociate', 'relieve', 'fears', 'hours', 'deceive', 'refolv', 'pursues', 'thought', 'morsel', 'brought', 'coquet', 'mistaken', 'maid', 'faithful', 'love', 'femalefalfe', 'lucre', 'fold', 'herself', 'vows', 'broken', 'laid', 'grave', 'constant', 'example', 'injur', 'truth', 'diflurbing', 'dreams', 'couch', 'annoy', 'dying', 'groans', 'peace', 'destroy', 'deep-', 'deep-rooted', 'guilt', 'bofomftains', 'spot', '-the-spot', 'remains', 'tears', 'wifllies', 'might', 'live', 'again', 'repentance', 'late', 'lasting', 'torment', 'fate', 'midnight-spec7re', 'wounds', 'help', 'friends', 'cries.', 'alive', 'thou', 'lhalt', 'mine', 'claim', 'resign', 'roars', 'snatches', 'vengeful', 'fiends', 'future', 'prey', 'confirm', 'print', 'view', 'examples', '-and', '§print', 'true', 'read', 'dismal', 'sleep', \"o'er\", 'goflips', 'bateman', 'loft', 'life', 'jermin', 'came', 'shades', 'below', 'bore', 'swift', 'horrour', \"ihudd'ring\", 'nymphs', 'mischiefs', 'wait', 'thirst', 'ruins', 'groves', 'restless', 'phant.m', 'pensive', 'roves', 'break', 'longs', 'speak', 'grief', 'reft', 'nothing', 'disdainful', 'turns', 'still', 'mual', 'indulge', 'hidden', 'sighing', 'mixes', 'thousand', 'monks', 'contriv', 'yore', 'tradition', 'handed', 'down', 'muse', 'weak', 'fright', 'clown', 'revolving', 'gropes', 'home', \"chris'mnas-a¢\", 'cheat', 'laugh', 'fond', 'conceit', 'spirits', 'judge', 'from-', 'monks-', 'our-selves', 'idle', 'fancies', 'range', 'harmless', 'pos7s', 'doemons', 'change', 'church-yaids', 'parson', 'mare', 'becomes', 'sprite', 'farrer', 'heifer', 'couching', 'made', 'fiend', 'sawicer', 'short', 'ideas', 'reason', 'beaten', 'station', 'gives', 'ground', 'wild', 'imagination', 'bred', 'towns', '-have', 'walks', 'frequent', 'phiantoms', 'lightly', 'swim', 'those', 'grotto', 'skim', 'thoft', 'said', 'name', 'comparison', 'worthy', 'blame', 'simple', 'deceptio', 'share', 'element', 'thence', 'power', 'uate', 'sense', 'compound', 'substantial', 'flejh', 'blood', 'felt', 'undersfood', 'fragrant', 'granted', 'syren', 'ttoice', 'fraught', 'blifi', 'dare', 'clasp', 'nameless', 'charms', 'aerial', 'baulks', 'your', 'arms', 'prays', 'fllines', 'balls', 'plays', 'radiant', 'circles', 'round', 'ring', 'goes', 'court', 'so10', 'masquerade', 'hear', 'evidently', 'fliown', 'inviting', 'known', 'note', 'rules', 'dispense', 'difguis', 'without', 'offence', 'skies', 'cloudless', 'bright', 'zephyrs', 'waft', 'country-air', 'winter', 'noon', 'summer', 'park', 'chief', 'delight', 'thro', 'vis/o', 'glide', 'kindred-phantom', 'side', 'silent', 'hfows', 'disclose', 'tender', 'breast', 'oppreft', \"'till\", 'brave', 'lvlhat', 'atnd', 'scenes', 'valiant', 'knight', 'hath', 'spoke', '-free', 'enchantment', 'broke', 'join', '-disclose', 'treasure', 'otheriwealth', 'surmount', 'arithmetick', 'count', 'leed', 'a-youth', 'childish', 'think', 'attiempt', 'cost', 'phtaatom', 'w..ks', 'relieves', 'talks', 'tyrant', '.custom', 'worse', 'says', \"ne'er\", 'begin', 'question', 'give.an', 'answer', 'conscious', 'bluflies', 'rife', 'sparkle', 'nature', 'deck', 'pride', 'shines', 'freih', 'aukvwards', 'bafhful', \"'swaini\", 'permits', 'rti.l', 'nonelre', 'whper', 'itse', \"hwoi'8loe\", 'e-ly', 'allits.gbeaties', 'rosy', 'fadsa', 'delightful', 'wanton', 'airs', 'foan', 'gie4bp.e', 'wrinkle¢dcates', 'it.willfpai', \"'itbfrom\", 'aimind', 'canker', 'withisfitre', 'mankind', 'each', 'iatil', \"'night\", \"'twill'vexaid\", 'pine', \"whole'ilife\", 'to.tales', 'nfign', 'iphan-toms', 'young', 'misf6otite', 'niever', 'flare', 'soon', 'theyjoy', 'sorrows', 'past', 'beauty', 'last', 'advised', \"e.a'cfibeft\", 'phantodm', 'smile']\n"
     ]
    }
   ],
   "source": [
    "# Just making sure the order is preserved:\n",
    "print(fnames[1890])\n",
    "print(wordLists[1890])\n",
    "print(test_features['0129500100.xml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97688\n"
     ]
    }
   ],
   "source": [
    "# Convert list of lists into list of strings (like 'everything' above)\n",
    "listOfStrings = [' '.join(str(word) for word in LIST) for LIST in wordLists]\n",
    "print(len(listOfStrings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pass it to CountVec now:\n",
    "X_test = vectorizer500.transform(listOfStrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97688, 2141835)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREDICTIONS = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97688\n",
      "['History' 'Law' 'Law' ... 'Politics' 'History' 'Politics']\n"
     ]
    }
   ],
   "source": [
    "print(len(PREDICTIONS))\n",
    "print(PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the predictions to filenames:\n",
    "\n",
    "FINAL_OUTPUT = {}\n",
    "\n",
    "for fname,pred in zip(fnames, PREDICTIONS):\n",
    "    FINAL_OUTPUT[fname] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0031300100.xml', '0031300200.xml', '0031300300.xml', '0031300400.xml']\n"
     ]
    }
   ],
   "source": [
    "print(fnames[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = '/Users/dh_lab_05/Desktop/Map_FileToLabel.pickle'\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(FINAL_OUTPUT, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
