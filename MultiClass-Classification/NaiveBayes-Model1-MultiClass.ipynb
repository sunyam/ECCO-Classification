{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Hyperparameter tuning for Naive Bayes.\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "def my_NB(X, labels):\n",
    "    \n",
    "    tuned_parameters = {'alpha': [1.0, 1e-3, 1e-6, 1e-12, 1e-18]}\n",
    "    \n",
    "    metrics = ['accuracy']\n",
    "    m = ['accuracy']\n",
    "#     m = ['precision_micro', 'f1_micro', 'accuracy', 'recall_micro']\n",
    "    models = []\n",
    "    \n",
    "    for score in metrics:\n",
    "        model = {}\n",
    "        nb = MultinomialNB()\n",
    "        print \"Running for\", score\n",
    "        clf = GridSearchCV(nb, tuned_parameters, cv=10, scoring=score, verbose=3)\n",
    "        clf.fit(X, labels)\n",
    "        print \"\\nBest parameters for \" + score + \": \" + str(clf.best_estimator_)\n",
    "        print \"Best score achieved for \" + score + \": \" + str(clf.best_score_)\n",
    "        best_nb = clf.best_estimator_\n",
    "        \n",
    "        for s in m:\n",
    "#             print \"Running the best \" + score + \" model for \" + s + \"..\"\n",
    "            model[s] = np.array(cross_val_score(best_nb, X, labels, cv=10, scoring=s))\n",
    "        \n",
    "#         print \"For \", score \n",
    "        print model\n",
    "#         print \"\\n\\n\"\n",
    "        models.append((model, best_nb))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything:  57231\n",
      "Count:  57231\n",
      "Vectorizer:  (57231, 66060)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load CSVs and getting it ready for CountVectorizer.\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "numberOfFeatures = 100\n",
    "\n",
    "# categories = ['Agriculture.csv', 'Biography.csv', 'Botany.csv', 'Church.csv', 'Commerce.csv', 'Dictionaries.csv', \n",
    "#               'Drama.csv', 'Fiction.csv', 'History.csv', 'History_Natural.csv', 'Law.csv', 'Mathematics.csv', \n",
    "#               'Medicine.csv', 'Physics.csv', 'Poetry.csv', 'Politics.csv', 'Rhetoric.csv', 'Sermons.csv', \n",
    "#               'Travels.csv']\n",
    "\n",
    "df_agri = pd.read_csv('./5_features/Model1_length1/agri_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "\n",
    "df_botany = pd.read_csv('./5_features/Model1_length1/botany_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_church = pd.read_csv('./5_features/Model1_length1/church_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_commerce = pd.read_csv('./5_features/Model1_length1/commerce_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_drama = pd.read_csv('./5_features/Model1_length1/drama_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_fiction = pd.read_csv('./5_features/Model1_length1/fiction_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_history = pd.read_csv('./5_features/Model1_length1/history_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_historyNatural = pd.read_csv('./5_features/Model1_length1/historyNatural_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_law = pd.read_csv('./5_features/Model1_length1/law_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_math = pd.read_csv('./5_features/Model1_length1/math_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_med = pd.read_csv('./5_features/Model1_length1/med_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_phy = pd.read_csv('./5_features/Model1_length1/phy_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_poetry = pd.read_csv('./5_features/Model1_length1/poetry_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_politics = pd.read_csv('./5_features/Model1_length1/politics_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_rhetoric = pd.read_csv('./5_features/Model1_length1/rhetoric_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_sermons = pd.read_csv('./5_features/Model1_length1/sermons_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "df_travels = pd.read_csv('./5_features/Model1_length1/travels_' + str(numberOfFeatures) + '.csv', header=None, names=range(0,numberOfFeatures))\n",
    "\n",
    "# Removing NaN\n",
    "df_agri.fillna('', inplace=True)\n",
    "\n",
    "df_botany.fillna('', inplace=True)\n",
    "df_church.fillna('', inplace=True)\n",
    "df_commerce.fillna('', inplace=True)\n",
    "df_drama.fillna('', inplace=True)\n",
    "df_fiction.fillna('', inplace=True)\n",
    "df_history.fillna('', inplace=True)\n",
    "df_historyNatural.fillna('', inplace=True)\n",
    "df_law.fillna('', inplace=True)\n",
    "df_math.fillna('', inplace=True)\n",
    "df_med.fillna('', inplace=True)\n",
    "df_phy.fillna('', inplace=True)\n",
    "df_poetry.fillna('', inplace=True)\n",
    "df_politics.fillna('', inplace=True)\n",
    "df_rhetoric.fillna('', inplace=True)\n",
    "df_sermons.fillna('', inplace=True)\n",
    "df_travels.fillna('', inplace=True)\n",
    "\n",
    "# Changing it to CountVec fashion:\n",
    "agri = [' '.join(str(r) for r in row) for row in df_agri.values]\n",
    "\n",
    "botany = [' '.join(str(r) for r in row) for row in df_botany.values]\n",
    "church = [' '.join(str(r) for r in row) for row in df_church.values]\n",
    "commerce = [' '.join(str(r) for r in row) for row in df_commerce.values]\n",
    "\n",
    "drama = [' '.join(str(r) for r in row) for row in df_drama.values]\n",
    "fiction = [' '.join(str(r) for r in row) for row in df_fiction.values]\n",
    "history = [' '.join(str(r) for r in row) for row in df_history.values]\n",
    "historyNatural = [' '.join(str(r) for r in row) for row in df_historyNatural.values]\n",
    "law = [' '.join(str(r) for r in row) for row in df_law.values]\n",
    "math = [' '.join(str(r) for r in row) for row in df_math.values]\n",
    "med = [' '.join(str(r) for r in row) for row in df_med.values]\n",
    "\n",
    "phy = [' '.join(str(r) for r in row) for row in df_phy.values]\n",
    "poetry = [' '.join(str(r) for r in row) for row in df_poetry.values]\n",
    "politics = [' '.join(str(r) for r in row) for row in df_politics.values]\n",
    "rhetoric = [' '.join(str(r) for r in row) for row in df_rhetoric.values]\n",
    "sermons = [' '.join(str(r) for r in row) for row in df_sermons.values]\n",
    "travels = [' '.join(str(r) for r in row) for row in df_travels.values]\n",
    "\n",
    "# Passing it to CountVectorizer:\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "everything = agri + botany + church + commerce + drama + fiction + history + historyNatural + law + math + med + \\\n",
    "             phy + poetry + politics + rhetoric + sermons + travels\n",
    "print \"Everything: \", len(everything)\n",
    "\n",
    "# Defining labels (must be in the same order)\n",
    "labels = len(agri)*['Agriculture'] + len(botany)*['Botany'] + len(church)*['Church'] + len(commerce)*['Commerce'] + len(drama)*['Drama'] + len(fiction)*['Fiction'] + len(history)*['History'] + len(historyNatural)*['History Natural'] + len(law)*['Law'] + len(math)*['Mathematics'] + len(med)*['Medicine'] + len(phy)*['Physics'] + len(poetry)*['Poetry'] + len(politics)*['Politics'] + len(rhetoric)*['Rhetoric'] + len(sermons)*['Sermons'] + len(travels)*['Travels']\n",
    "\n",
    "# Storing sizes (in same order)\n",
    "sizes_in_same_order = [len(agri), len(botany), len(church), len(commerce), len(drama), len(fiction), len(history), len(historyNatural), len(law), len(math), len(med), len(phy), len(poetry), len(politics), len(rhetoric), len(sermons), len(travels)]\n",
    "\n",
    "count = 0\n",
    "for i in sizes_in_same_order:\n",
    "    count += i\n",
    "print \"Count: \", count\n",
    "\n",
    "vectorizer500 = CountVectorizer()\n",
    "X500 = vectorizer500.fit_transform(everything)\n",
    "print \"Vectorizer: \", X500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for accuracy\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ................... alpha=1.0, score=0.64829030007, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... alpha=1.0, score=0.71279008899, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. alpha=1.0, score=0.706077541041, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .................. alpha=1.0, score=0.715583508036, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .................. alpha=1.0, score=0.698706745893, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .................. alpha=1.0, score=0.665443104352, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .................. alpha=1.0, score=0.657577346618, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .................. alpha=1.0, score=0.697849274349, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .................. alpha=1.0, score=0.596537250787, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ................... alpha=1.0, score=0.47315025363, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................. alpha=0.001, score=0.69330076762, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................ alpha=0.001, score=0.761647181993, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................ alpha=0.001, score=0.758644778205, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................ alpha=0.001, score=0.764500349406, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................. alpha=0.001, score=0.75760223698, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................ alpha=0.001, score=0.714735186156, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................ alpha=0.001, score=0.710540115364, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................ alpha=0.001, score=0.749256863088, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................ alpha=0.001, score=0.639909059112, total=   0.3s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ................ alpha=0.001, score=0.500612209201, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.701849267271, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.764264526261, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.763709395739, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.769217330538, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.755854596295, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.714909980773, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.716308337703, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.751005420528, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.647429171039, total=   0.3s\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] ................ alpha=1e-06, score=0.508308553437, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunyambagga/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=1e-12, score=0.706036287509, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.758331879253, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.758295494237, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.761879804333, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.751835022719, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.706869428422, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.710714909981, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.740863787375, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.644106330885, total=   0.3s\n",
      "[CV] alpha=1e-12 .....................................................\n",
      "[CV] ................ alpha=1e-12, score=0.506209550464, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.706036287509, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.758331879253, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.758295494237, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.761879804333, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.751835022719, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.706869428422, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.710714909981, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.740863787375, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.644106330885, total=   0.3s\n",
      "[CV] alpha=1e-18 .....................................................\n",
      "[CV] ................ alpha=1e-18, score=0.506209550464, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for accuracy: MultinomialNB(alpha=1e-06, class_prior=None, fit_prior=True)\n",
      "Best score achieved for accuracy: 0.7093183764043962\n",
      "{'accuracy': array([0.70184927, 0.76426453, 0.7637094 , 0.76921733, 0.7558546 ,\n",
      "       0.71490998, 0.71630834, 0.75100542, 0.64742917, 0.50830855])}\n",
      "\n",
      "Accuracy:  0.7092856579583766\n",
      "Std-dev:  0.07605254870075309\n"
     ]
    }
   ],
   "source": [
    "results_500 = my_NB(X500, labels)\n",
    "print \"\\nAccuracy: \", results_500[0][0]['accuracy'].mean()\n",
    "print \"Std-dev: \", results_500[0][0]['accuracy'].std()\n",
    "# print \"Best hyperparams: \", results_500[0][1]\n",
    "# print \"Entire array: \", results_500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
