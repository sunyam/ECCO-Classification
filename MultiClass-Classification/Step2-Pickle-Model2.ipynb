{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2: All words > len(3)\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "\n",
    "'''\n",
    "Takes in a list of sentences where each sentence is a list of words, and optional argument 'user_stopwords'.\n",
    "Returns a dictionary with each 'word' is the key, and 'count' as the value.\n",
    "'''\n",
    "def calculate_frequencies(sentences_ll, user_stopwords=None):  # sentences_ll is a list of lists\n",
    "    frequency = defaultdict(int)    # default value : 0\n",
    "    \n",
    "    for sentence in sentences_ll:\n",
    "        for word in sentence:\n",
    "            word = word.lower()\n",
    "            \n",
    "            if len(word) > 3:\n",
    "                frequency[word] += 1\n",
    "\n",
    "    return frequency\n",
    "\n",
    "'''\n",
    "Takes in text, and n = number of features\n",
    "Returns a list of n most frequent words\n",
    "'''\n",
    "def get_features(text, n, user_stopwords=None):  # n is the desired no. of features\n",
    "    sentences = sent_tokenize(text.decode('utf8'))\n",
    "    \n",
    "    sentences_ll = []\n",
    "    for s in sentences:\n",
    "        words = word_tokenize(s)\n",
    "        sentences_ll.append(words)\n",
    "\n",
    "    frequency = calculate_frequencies(sentences_ll, user_stopwords)\n",
    "    return nlargest(n, frequency, key=frequency.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./5.0_folder_fn_label_tuples.pickle', 'rb') as f:\n",
    "    fo_fn_label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n"
     ]
    }
   ],
   "source": [
    "numberOfFeatures = 100\n",
    "# They are a list of lists where each list represents a document as a collection of n frequent words.\n",
    "\n",
    "categories = ['Agriculture.csv', 'Biography.csv', 'Botany.csv', 'Church.csv', 'Commerce.csv', 'Dictionaries.csv', \n",
    "              'Drama.csv', 'Fiction.csv', 'History.csv', 'History_Natural.csv', 'Law.csv', 'Mathematics.csv', \n",
    "              'Medicine.csv', 'Physics.csv', 'Poetry.csv', 'Politics.csv', 'Rhetoric.csv', 'Sermons.csv', \n",
    "              'Travels.csv']\n",
    "\n",
    "features_agri = []\n",
    "features_bio = []\n",
    "features_botany = []\n",
    "features_church = []\n",
    "features_commerce = []\n",
    "features_dictionaries = []\n",
    "features_drama = []\n",
    "features_fiction = []\n",
    "features_history = []\n",
    "features_historynatural = []\n",
    "features_law = []\n",
    "features_math = []\n",
    "features_med = []\n",
    "features_phy = []\n",
    "features_poetry = []\n",
    "features_politics = []\n",
    "features_rhetoric = []\n",
    "features_sermons = []\n",
    "features_travels = []\n",
    "\n",
    "k = 0\n",
    "for (folder, fn, label) in fo_fn_label:\n",
    "    if k % 1000 == 0:\n",
    "        print k\n",
    "        \n",
    "    k += 1\n",
    "    if label == 'Agriculture':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_agri.append(get_features(text, numberOfFeatures))\n",
    "     \n",
    "    elif label == 'Biography':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_bio.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Botany':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_botany.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Church':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_church.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Commerce':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_commerce.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Dictionaries':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_dictionaries.append(get_features(text, numberOfFeatures))\n",
    "            \n",
    "#              ['Agriculture.csv', 'Biography.csv', 'Botany.csv', 'Church.csv', 'Commerce.csv', 'Dictionaries.csv', \n",
    "#               'Drama.csv', 'Fiction.csv', 'History.csv', 'History_Natural.csv', 'Law.csv', 'Mathematics.csv', \n",
    "#               'Medicine.csv', 'Physics.csv', 'Poetry.csv', 'Politics.csv', 'Rhetoric.csv', 'Sermons.csv', \n",
    "#               'Travels.csv']\n",
    "            \n",
    "    elif label == 'Drama':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_drama.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Fiction':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_fiction.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'History':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_history.append(get_features(text, numberOfFeatures))\n",
    "            \n",
    "    elif label == 'History_Natural':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_historynatural.append(get_features(text, numberOfFeatures))\n",
    "            \n",
    "    elif label == 'Law':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_law.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Mathematics':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_math.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Medicine':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_med.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Physics':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_phy.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Poetry':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_poetry.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Politics':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_politics.append(get_features(text, numberOfFeatures))\n",
    "            \n",
    "    elif label == 'Rhetoric':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_rhetoric.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Sermons':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_sermons.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    elif label == 'Travels':\n",
    "        with open('../Dataset/' + folder + '/' + fn) as f:\n",
    "            text = f.read()\n",
    "            features_travels.append(get_features(text, numberOfFeatures))\n",
    "\n",
    "    else:\n",
    "        print \"This is interesting: \", label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66472\n"
     ]
    }
   ],
   "source": [
    "# Checking if all files have been vectorised. They should all sum to 66,472:\n",
    "\n",
    "print len(features_agri) + \\\n",
    "len(features_bio) + \\\n",
    "len(features_botany) + \\\n",
    "len(features_church) + \\\n",
    "len(features_commerce) + \\\n",
    "len(features_dictionaries) + \\\n",
    "len(features_drama) + \\\n",
    "len(features_fiction) + \\\n",
    "len(features_history) + \\\n",
    "len(features_historynatural) + \\\n",
    "len(features_law) + \\\n",
    "len(features_math) + \\\n",
    "len(features_med) + \\\n",
    "len(features_phy) + \\\n",
    "len(features_poetry) + \\\n",
    "len(features_politics) + \\\n",
    "len(features_rhetoric) + \\\n",
    "len(features_sermons) + \\\n",
    "len(features_travels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickling doesn't work; Writing to CSVs\n",
    "\n",
    "import unicodecsv as csv\n",
    "\n",
    "with open('./5_features/Model2_length3/agri_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f, encoding='utf-8')\n",
    "    writer.writerows(features_agri)\n",
    "    \n",
    "with open('./5_features/Model2_length3/biography_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_bio)\n",
    "    \n",
    "with open('./5_features/Model2_length3/botany_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_botany)\n",
    "    \n",
    "with open('./5_features/Model2_length3/church_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_church)\n",
    "    \n",
    "with open('./5_features/Model2_length3/commerce_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_commerce)\n",
    "    \n",
    "with open('./5_features/Model2_length3/dict_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_dictionaries)\n",
    "    \n",
    "with open('./5_features/Model2_length3/drama_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_drama)\n",
    "    \n",
    "with open('./5_features/Model2_length3/fiction_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_fiction)\n",
    "    \n",
    "with open('./5_features/Model2_length3/history_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_history)\n",
    "\n",
    "with open('./5_features/Model2_length3/historyNatural_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_historynatural)\n",
    "    \n",
    "with open('./5_features/Model2_length3/law_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_law)\n",
    "\n",
    "with open('./5_features/Model2_length3/math_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_math)\n",
    "    \n",
    "with open('./5_features/Model2_length3/med_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_med)\n",
    "        \n",
    "with open('./5_features/Model2_length3/phy_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_phy)\n",
    "    \n",
    "with open('./5_features/Model2_length3/poetry_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_poetry)\n",
    "    \n",
    "with open('./5_features/Model2_length3/politics_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_politics)\n",
    "    \n",
    "with open('./5_features/Model2_length3/rhetoric_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_rhetoric)\n",
    "    \n",
    "with open('./5_features/Model2_length3/sermons_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_sermons)\n",
    "    \n",
    "with open('./5_features/Model2_length3/travels_'+str(numberOfFeatures)+'.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(features_travels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
