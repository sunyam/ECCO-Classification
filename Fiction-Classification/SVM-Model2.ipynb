{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_load(n):\n",
    "    with open('./features/Model2_no_stopwords/fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        fic = pickle.load(f)\n",
    "\n",
    "    with open('./features/Model2_no_stopwords/non_fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        nonfic = pickle.load(f)\n",
    "\n",
    "    return fic, nonfic\n",
    "\n",
    "fic50, nonfic50     = pickle_load(50)\n",
    "fic100, nonfic100   = pickle_load(100)\n",
    "fic500, nonfic500   = pickle_load(500)\n",
    "fic1000, nonfic1000 = pickle_load(1000)\n",
    "fic3000, nonfic3000 = pickle_load(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Different hyper-parameters in SVM.\n",
    "'''\n",
    "def my_SVM(X):\n",
    "    # Getting labels ready: 1 is for Fiction, 0 is for NonFiction\n",
    "    labels = [1]*4558 + [0]*4558\n",
    "    \n",
    "    tuned_parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']}, \n",
    "                        {'C': [1, 10, 100, 1000], 'gamma': ['auto', 0.001, 0.0001], 'kernel': ['rbf']}]\n",
    "    \n",
    "    metrics = ['f1']\n",
    "    m = ['precision', 'f1', 'accuracy', 'recall']\n",
    "    \n",
    "    # List of 4 dictionaries, where each dictionary represents all the results for that particular best model.\n",
    "    models = []\n",
    "    \n",
    "    for score in metrics:\n",
    "        model = {}\n",
    "        svc = SVC()\n",
    "        print \"Running for \", score\n",
    "        clf = GridSearchCV(svc, tuned_parameters, cv=10, scoring=score, verbose=2)\n",
    "        clf.fit(X, labels)\n",
    "        print \"\\nBest parameters for \" + score + \": \" + str(clf.best_estimator_)\n",
    "        print \"Best score achieved for \" + score + \": \" + str(clf.best_score_)\n",
    "        best_svc = clf.best_estimator_\n",
    "        # Now that I have the best parameters for each metric, running SVM for those specific parameters to obtain \n",
    "        # all values.\n",
    "        for s in m:\n",
    "            print \"Running the best \" + score + \" model for \" + s + \"..\"\n",
    "            model[s] = np.array(cross_val_score(best_svc, X, labels, cv=10, scoring=s))\n",
    "        \n",
    "        print \"For \", score \n",
    "        print model\n",
    "        print \"\\n\\n\"\n",
    "        models.append(model)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "'''\n",
    "For 50:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction50 = []\n",
    "countvec_nonfiction50 = []\n",
    "\n",
    "for doc in fic50:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction50.append(temp)\n",
    "    \n",
    "for doc in nonfic50:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction50.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction50 = countvec_fiction50 + countvec_nonfiction50\n",
    "    \n",
    "vectorizer50 = CountVectorizer()\n",
    "\n",
    "X50 = vectorizer50.fit_transform(fiction_plus_nonfiction50)\n",
    "\n",
    "results_50 = my_SVM(X50)\n",
    "print \"Done for 50\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "'''\n",
    "For 100:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction100 = []\n",
    "countvec_nonfiction100 = []\n",
    "\n",
    "for doc in fic100:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction100.append(temp)\n",
    "    \n",
    "for doc in nonfic100:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction100.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction100 = countvec_fiction100 + countvec_nonfiction100\n",
    "    \n",
    "vectorizer100 = CountVectorizer()\n",
    "X100 = vectorizer100.fit_transform(fiction_plus_nonfiction100)\n",
    "\n",
    "results_100 = my_SVM(X100)\n",
    "print \"Done for 100\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "\n",
    "'''\n",
    "For 500:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction500 = []\n",
    "countvec_nonfiction500 = []\n",
    "\n",
    "for doc in fic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction500.append(temp)\n",
    "    \n",
    "for doc in nonfic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction500.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction500 = countvec_fiction500 + countvec_nonfiction500\n",
    "    \n",
    "vectorizer500 = CountVectorizer()\n",
    "X500 = vectorizer500.fit_transform(fiction_plus_nonfiction500)\n",
    "\n",
    "results_500 = my_SVM(X500)\n",
    "print \"Done for 500\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 1000:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction1000 = []\n",
    "countvec_nonfiction1000 = []\n",
    "\n",
    "for doc in fic1000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction1000.append(temp)\n",
    "    \n",
    "for doc in nonfic1000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction1000.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction1000 = countvec_fiction1000 + countvec_nonfiction1000\n",
    "    \n",
    "vectorizer1000 = CountVectorizer()\n",
    "X1000 = vectorizer1000.fit_transform(fiction_plus_nonfiction1000)\n",
    "\n",
    "results_1000 = my_SVM(X1000)\n",
    "print \"Done for 1000\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 3000:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction3000 = []\n",
    "countvec_nonfiction3000 = []\n",
    "\n",
    "for doc in fic3000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction3000.append(temp)\n",
    "    \n",
    "for doc in nonfic3000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction3000.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction3000 = countvec_fiction3000 + countvec_nonfiction3000\n",
    "    \n",
    "vectorizer3000 = CountVectorizer()\n",
    "X3000 = vectorizer3000.fit_transform(fiction_plus_nonfiction3000)\n",
    "\n",
    "results_3000 = my_SVM(X3000)\n",
    "print \"Done for 3000\\n\"\n",
    "print \"######################################################\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just experimenting with Lemmatization:\n",
    "\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# lemm = WordNetLemmatizer()\n",
    "\n",
    "# new_fic500 = []\n",
    "# new_nonfic500 = []\n",
    "\n",
    "# for sent in fic500:\n",
    "#     temp = []\n",
    "#     for w in sent:\n",
    "#         temp.append(lemm.lemmatize(w))\n",
    "#     new_fic500.append(temp)\n",
    "\n",
    "\n",
    "# for sent in nonfic500:\n",
    "#     temp = []\n",
    "#     for w in sent:\n",
    "#         temp.append(lemm.lemmatize(w))\n",
    "#     new_nonfic500.append(temp)\n",
    "    \n",
    "\n",
    "# print len(fic500)\n",
    "# print len(new_fic500)\n",
    "# print len(nonfic500)\n",
    "# print len(new_nonfic500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for  f1\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.4min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.5min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.5min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.5min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.6min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.7min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.7min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.8min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.8min\n",
      "[CV] kernel=rbf, C=10, gamma=auto ....................................\n",
      "[CV] ........................... kernel=rbf, C=10, gamma=auto - 2.7min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.8min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 2.0min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=10, gamma=0.001 ...................................\n",
      "[CV] .......................... kernel=rbf, C=10, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.4min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.6min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.6min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.5min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.5min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.5min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.5min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.5min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.5min\n",
      "[CV] kernel=rbf, C=1000, gamma=auto ..................................\n",
      "[CV] ......................... kernel=rbf, C=1000, gamma=auto - 1.5min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 1.9min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.0min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.1min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.3min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.5min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.2min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.2min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.2min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.3min\n",
      "[CV] kernel=rbf, C=1000, gamma=0.001 .................................\n",
      "[CV] ........................ kernel=rbf, C=1000, gamma=0.001 - 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 82.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Best score achieved for f1: 0.967469280934\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.90789474,  0.99561404,  0.99342105,  0.99561404,  0.95394737,\n",
      "        0.96929825,  0.9495614 ,  0.97149123,  0.92747253,  0.87692308]), 'f1': array([ 0.94628571,  0.99234973,  0.9869281 ,  0.99018539,  0.96989967,\n",
      "        0.97464168,  0.96759777,  0.97469747,  0.95367232,  0.91829689]), 'precision': array([ 0.98806683,  0.98910675,  0.98051948,  0.98481562,  0.98639456,\n",
      "        0.98004435,  0.98633257,  0.97792494,  0.98139535,  0.96376812]), 'accuracy': array([ 0.94846491,  0.99232456,  0.98684211,  0.99013158,  0.97039474,\n",
      "        0.9747807 ,  0.96820175,  0.9747807 ,  0.95494505,  0.92197802])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 500\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "For 500:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction500 = []\n",
    "countvec_nonfiction500 = []\n",
    "\n",
    "for doc in new_fic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction500.append(temp)\n",
    "    \n",
    "for doc in new_nonfic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction500.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction500 = countvec_fiction500 + countvec_nonfiction500\n",
    "    \n",
    "vectorizer500 = CountVectorizer()\n",
    "X500 = vectorizer500.fit_transform(fiction_plus_nonfiction500)\n",
    "\n",
    "results_500 = my_SVM(X500)\n",
    "print \"Done for 500\\n\"\n",
    "print \"######################################################\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967455471865\n"
     ]
    }
   ],
   "source": [
    "print results_500[0]['f1'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
