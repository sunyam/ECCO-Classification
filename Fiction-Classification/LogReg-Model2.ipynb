{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_load(n):\n",
    "    with open('./features/Model2_no_stopwords/fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        fic = pickle.load(f)\n",
    "\n",
    "    with open('./features/Model2_no_stopwords/non_fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        nonfic = pickle.load(f)\n",
    "\n",
    "    return fic, nonfic\n",
    "\n",
    "fic50, nonfic50     = pickle_load(50)\n",
    "fic100, nonfic100   = pickle_load(100)\n",
    "fic500, nonfic500   = pickle_load(500)\n",
    "fic1000, nonfic1000 = pickle_load(1000)\n",
    "fic3000, nonfic3000 = pickle_load(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Different hyper-parameters in Logistic Regression.\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def my_LogReg(X):\n",
    "    # Getting labels ready: 1 is for Fiction, 0 is for NonFiction\n",
    "    labels = [1]*4558 + [0]*4558\n",
    "    \n",
    "    tuned_parameters = [{'C': [1, 10, 100, 1000], 'penalty': ['l1'], 'solver': ['liblinear']}, \n",
    "                        {'C': [1, 10, 100, 1000], 'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'sag']}]\n",
    "    metrics = ['f1']\n",
    "    m = ['precision', 'f1', 'accuracy', 'recall']\n",
    "    \n",
    "    # List of 4 dictionaries, where each dictionary represents all the results for that particular best model.\n",
    "    models = []\n",
    "    \n",
    "    for score in metrics:\n",
    "        model = {}\n",
    "        lr = LogisticRegression()\n",
    "        print \"Running for \", score\n",
    "        clf = GridSearchCV(lr, tuned_parameters, cv=10, scoring=score, verbose=1)\n",
    "        clf.fit(X, labels)\n",
    "        print \"\\nBest parameters for \" + score + \": \" + str(clf.best_estimator_)\n",
    "        print \"Best score achieved for \" + score + \": \" + str(clf.best_score_)\n",
    "        best_lr = clf.best_estimator_\n",
    "        \n",
    "        for s in m:\n",
    "            print \"Running the best \" + score + \" model for \" + s + \"..\"\n",
    "            model[s] = np.array(cross_val_score(best_lr, X, labels, cv=10, scoring=s))\n",
    "        \n",
    "        print \"For \", score \n",
    "        print model\n",
    "        print \"\\n\\n\"\n",
    "        models.append(model)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunyambagga/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/sunyambagga/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunyambagga/anaconda/lib/python2.7/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.953743629563\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.89254386,  0.98684211,  0.98245614,  0.99561404,  0.95175439,\n",
      "        0.95175439,  0.94517544,  0.96710526,  0.90989011,  0.87032967]), 'f1': array([ 0.92710706,  0.97932535,  0.97180043,  0.97950378,  0.96124031,\n",
      "        0.95911602,  0.95248619,  0.95973885,  0.93559322,  0.91139241]), 'precision': array([ 0.96445498,  0.97192225,  0.96137339,  0.96390658,  0.97091723,\n",
      "        0.96659243,  0.95991091,  0.9524838 ,  0.9627907 ,  0.95652174]), 'accuracy': array([ 0.92982456,  0.97916667,  0.97149123,  0.97916667,  0.96162281,\n",
      "        0.95942982,  0.95285088,  0.95942982,  0.93736264,  0.91538462])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 50\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n",
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.957330346503\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.89912281,  0.99342105,  0.99122807,  0.99122807,  0.95175439,\n",
      "        0.95394737,  0.95175439,  0.96710526,  0.91648352,  0.86153846]), 'f1': array([ 0.92865232,  0.99016393,  0.9826087 ,  0.97941495,  0.96017699,\n",
      "        0.96559378,  0.95594714,  0.96078431,  0.94450736,  0.90531178]), 'precision': array([ 0.96018735,  0.9869281 ,  0.97413793,  0.96788009,  0.96875   ,\n",
      "        0.97752809,  0.96017699,  0.95454545,  0.97429907,  0.95377129]), 'accuracy': array([ 0.93092105,  0.99013158,  0.98245614,  0.97916667,  0.96052632,\n",
      "        0.96600877,  0.95614035,  0.96052632,  0.94615385,  0.90989011])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 100\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n",
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 28.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.965762314073\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.91008772,  0.99561404,  0.99342105,  0.99780702,  0.95614035,\n",
      "        0.96052632,  0.94517544,  0.97368421,  0.92967033,  0.87912088]), 'f1': array([ 0.94640821,  0.99018539,  0.9869281 ,  0.98698482,  0.97104677,\n",
      "        0.96688742,  0.96205357,  0.97368421,  0.95377678,  0.91954023]), 'precision': array([ 0.98574822,  0.98481562,  0.98051948,  0.97639485,  0.98642534,\n",
      "        0.97333333,  0.97954545,  0.97368421,  0.97916667,  0.96385542]), 'accuracy': array([ 0.94846491,  0.99013158,  0.98684211,  0.98684211,  0.97149123,\n",
      "        0.96710526,  0.9627193 ,  0.97368421,  0.95494505,  0.92307692])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 500\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n",
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 61.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.965480676235\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.91666667,  0.99122807,  0.99342105,  0.99561404,  0.95394737,\n",
      "        0.9627193 ,  0.95614035,  0.96491228,  0.92747253,  0.86593407]), 'f1': array([ 0.94570136,  0.98905908,  0.98585419,  0.98803047,  0.97098214,\n",
      "        0.97555556,  0.96460177,  0.97345133,  0.94938133,  0.91203704]), 'precision': array([ 0.97663551,  0.98689956,  0.97840173,  0.98056156,  0.98863636,\n",
      "        0.98873874,  0.97321429,  0.98214286,  0.97235023,  0.96332518]), 'accuracy': array([ 0.94736842,  0.98903509,  0.98574561,  0.9879386 ,  0.97149123,\n",
      "        0.97587719,  0.96491228,  0.97368421,  0.95054945,  0.91648352])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 1000\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n",
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 267.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.964867161461\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.91447368,  0.98903509,  0.99342105,  0.99780702,  0.95833333,\n",
      "        0.95833333,  0.95175439,  0.96929825,  0.92747253,  0.86593407]), 'f1': array([ 0.94677237,  0.98579235,  0.9826087 ,  0.98803047,  0.96895787,\n",
      "        0.97009967,  0.96222222,  0.9726776 ,  0.94903737,  0.9228972 ]), 'precision': array([ 0.97423888,  0.97830803,  0.98264642,  0.97639485,  0.97972973,\n",
      "        0.97544643,  0.97959184,  0.97161572,  0.97882353,  0.98743719]), 'accuracy': array([ 0.94407895,  0.98355263,  0.98135965,  0.98903509,  0.96820175,\n",
      "        0.96710526,  0.96491228,  0.9747807 ,  0.95384615,  0.92417582])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 3000\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "'''\n",
    "For 50:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction50 = []\n",
    "countvec_nonfiction50 = []\n",
    "\n",
    "for doc in fic50:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction50.append(temp)\n",
    "    \n",
    "for doc in nonfic50:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction50.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction50 = countvec_fiction50 + countvec_nonfiction50\n",
    "    \n",
    "vectorizer50 = CountVectorizer()\n",
    "X50 = vectorizer50.fit_transform(fiction_plus_nonfiction50)\n",
    "\n",
    "results_50 = my_LogReg(X50)\n",
    "print \"Done for 50\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 100:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction100 = []\n",
    "countvec_nonfiction100 = []\n",
    "\n",
    "for doc in fic100:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction100.append(temp)\n",
    "    \n",
    "for doc in nonfic100:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction100.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction100 = countvec_fiction100 + countvec_nonfiction100\n",
    "    \n",
    "vectorizer100 = CountVectorizer()\n",
    "X100 = vectorizer100.fit_transform(fiction_plus_nonfiction100)\n",
    "\n",
    "results_100 = my_LogReg(X100)\n",
    "print \"Done for 100\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "\n",
    "'''\n",
    "For 500:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction500 = []\n",
    "countvec_nonfiction500 = []\n",
    "\n",
    "for doc in fic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction500.append(temp)\n",
    "    \n",
    "for doc in nonfic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction500.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction500 = countvec_fiction500 + countvec_nonfiction500\n",
    "    \n",
    "vectorizer500 = CountVectorizer()\n",
    "X500 = vectorizer500.fit_transform(fiction_plus_nonfiction500)\n",
    "\n",
    "results_500 = my_LogReg(X500)\n",
    "print \"Done for 500\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 1000:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction1000 = []\n",
    "countvec_nonfiction1000 = []\n",
    "\n",
    "for doc in fic1000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction1000.append(temp)\n",
    "    \n",
    "for doc in nonfic1000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction1000.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction1000 = countvec_fiction1000 + countvec_nonfiction1000\n",
    "    \n",
    "vectorizer1000 = CountVectorizer()\n",
    "X1000 = vectorizer1000.fit_transform(fiction_plus_nonfiction1000)\n",
    "\n",
    "results_1000 = my_LogReg(X1000)\n",
    "print \"Done for 1000\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 3000:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction3000 = []\n",
    "countvec_nonfiction3000 = []\n",
    "\n",
    "for doc in fic3000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction3000.append(temp)\n",
    "    \n",
    "for doc in nonfic3000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction3000.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction3000 = countvec_fiction3000 + countvec_nonfiction3000\n",
    "    \n",
    "vectorizer3000 = CountVectorizer()\n",
    "X3000 = vectorizer3000.fit_transform(fiction_plus_nonfiction3000)\n",
    "\n",
    "results_3000 = my_LogReg(X3000)\n",
    "print \"Done for 3000\\n\"\n",
    "print \"######################################################\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
