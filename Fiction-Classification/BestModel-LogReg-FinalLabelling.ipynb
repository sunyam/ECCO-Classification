{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_load(n):\n",
    "    with open('./features/Model2_no_stopwords/fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        fic = pickle.load(f)\n",
    "\n",
    "    with open('./features/Model2_no_stopwords/non_fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        nonfic = pickle.load(f)\n",
    "\n",
    "    return fic, nonfic\n",
    "\n",
    "fic500, nonfic500   = pickle_load(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "'''\n",
    "For 500:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction500 = []\n",
    "countvec_nonfiction500 = []\n",
    "\n",
    "for doc in fic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction500.append(temp)\n",
    "    \n",
    "for doc in nonfic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction500.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction500 = countvec_fiction500 + countvec_nonfiction500\n",
    "    \n",
    "vectorizer500 = CountVectorizer()\n",
    "X500 = vectorizer500.fit_transform(fiction_plus_nonfiction500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9116, 154749)\n",
      "9116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X500.shape\n",
    "labels = [1]*4558 + [0]*4558\n",
    "print len(labels)\n",
    "# Train LogReg Model 2 for 500 words:\n",
    "model = LogisticRegression(C=1000, penalty='l2', solver='lbfgs')\n",
    "model.fit(X500, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15036, 154749)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculating CountVec feature vectors for test-fiction-big.\n",
    "'''\n",
    "\n",
    "with open('./features/test_big_fiction_500_Model2.pickle', 'rb') as f:\n",
    "    features_fiction_big = pickle.load(f)\n",
    "\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_500 = []\n",
    "\n",
    "for doc in features_fiction_big:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_500.append(temp)\n",
    "    \n",
    "Xtest_500 = vectorizer500.transform(countvec_500)\n",
    "\n",
    "print Xtest_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528198989093\n"
     ]
    }
   ],
   "source": [
    "# Now, predicting:\n",
    "predictions = model.predict(Xtest_500)\n",
    "\n",
    "# Calculating accuracy (assuming all is fiction in Fiction_big)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "true = [1]*15036\n",
    "print accuracy_score(true, predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "Confidence threshold:\n",
    "'''\n",
    "class_probabilities = model.predict_proba(Xtest_500)\n",
    "\n",
    "# NOTE: pred[0] corresponds to 0 (Non-fiction); and pred[1] corresponds to 1 (Fiction)\n",
    "fic_count = 0    # for when it was bloody sure\n",
    "nonfic_count = 0\n",
    "umm = 0\n",
    "\n",
    "confidence_threshold = 0.9\n",
    "\n",
    "for pred in class_probabilities:\n",
    "    if pred[1] > confidence_threshold:\n",
    "        fic_count += 1\n",
    "    elif pred[0] > confidence_threshold:\n",
    "        nonfic_count += 1\n",
    "    else:    # Not so sure about either\n",
    "        umm += 1\n",
    "        \n",
    "total = float(fic_count + nonfic_count + umm)\n",
    "print \"Out of a total:    \", total\n",
    "\n",
    "print \"Not so sure about: \", 100*umm/total\n",
    "print \"Surely nonfiction: \", 100*nonfic_count/total\n",
    "print \"Surely fiction:    \", 100*fic_count/total"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "Ignore this cell: Tried it with the best NB model. Gave 37%.\n",
    "'''\n",
    "import pickle\n",
    "\n",
    "def pickle_load(n):\n",
    "    with open('./features/Model3_all_stopwords_and_noPunc6/fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        fic = pickle.load(f)\n",
    "\n",
    "    with open('./features/Model3_all_stopwords_and_noPunc6/non_fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        nonfic = pickle.load(f)\n",
    "\n",
    "    return fic, nonfic\n",
    "\n",
    "fic50, nonfic50   = pickle_load(50)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(1e-3)\n",
    "nb.fit(X500, labels)\n",
    "\n",
    "# Now, predicting:\n",
    "predictions = nb.predict(Xtest_500)\n",
    "\n",
    "# Calculating accuracy (assuming all is fiction in Fiction_big)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "true = [1]*15036\n",
    "print accuracy_score(true, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the order:\n",
    "import pickle\n",
    "\n",
    "# Code to pickle this in Pickle-FictionBig-Model2 notebook:\n",
    "with open('./order_fiction.pickle', 'rb') as f:\n",
    "    order_fiction = pickle.load(f)\n",
    "print order_fiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15036\n",
      "15036\n",
      "[(('0000200100.xml.txt', 'LitAndLang_1'), 1), (('0000200200.xml.txt', 'LitAndLang_1'), 1), (('0000200400.xml.txt', 'LitAndLang_1'), 1), (('0000200500.xml.txt', 'LitAndLang_1'), 1)]\n"
     ]
    }
   ],
   "source": [
    "print len(order_fiction)\n",
    "print len(predictions)\n",
    "main = zip(order_fiction, predictions)\n",
    "print main[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7942\n"
     ]
    }
   ],
   "source": [
    "final_fiction = []\n",
    "\n",
    "# main has filename + its prediction\n",
    "for tup, p in main:\n",
    "    if p == 1:\n",
    "        final_fiction.append(tup)\n",
    "        \n",
    "print len(final_fiction)\n",
    "# print final_fiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7942\n"
     ]
    }
   ],
   "source": [
    "finalfiction_fnames = list(zip(*final_fiction)[0])\n",
    "print len(finalfiction_fnames)\n",
    "# print finalfiction_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Writing these final fiction filenames to the FINAL OUTPUT dataframe.\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "final_fic_fnames = [f[:-4] for f in finalfiction_fnames]\n",
    "\n",
    "fiction_big = pd.read_csv('./Fiction_Big.csv')\n",
    "\n",
    "FinalFiction = fiction_big.loc[fiction_big['Filename'].isin(final_fic_fnames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FinalFiction has 7942 rows (that were predicted by model). Adding the remaining 665 that were not present in \n",
    "# fiction_big but were present in fiction_small. For detailed analysis of that, see the last three cells of this \n",
    "# notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n",
      "['0003900900.xml', '0004700401.xml', '0004700402.xml', '0004700403.xml', '0007901400.xml', '0076201200.xml', '0079600800.xml', '0086000501.xml']\n"
     ]
    }
   ],
   "source": [
    "fiction_small = pd.read_csv('./Fiction_Small.csv')\n",
    "fnames_fiction_small = fiction_small['Filename'].tolist()\n",
    "\n",
    "count = 0\n",
    "notinfinal_butinsmall = []\n",
    "for fn in fnames_fiction_small:\n",
    "    if fn not in final_fic_fnames:\n",
    "        count += 1\n",
    "        notinfinal_butinsmall.append(fn)\n",
    "print count\n",
    "print notinfinal_butinsmall[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotInFinal_ButInSmall = fiction_small.loc[fiction_small['Filename'].isin(notinfinal_butinsmall)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the predicted in fiction_big and NotInFinalButInSmall\n",
    "FINAL_OUTPUT = pd.concat([FinalFiction, NotInFinal_ButInSmall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8607\n",
      "Filename          8607\n",
      "DocumentID        8607\n",
      "ESTC_ID           5685\n",
      "Date               105\n",
      "Title             5268\n",
      "Vol_Number          25\n",
      "Author            1530\n",
      "Imprint           5356\n",
      "Field_Headings    2033\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print 7942+665\n",
    "print FINAL_OUTPUT.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing to csv\n",
    "FINAL_OUTPUT.to_csv('./FINAL_FICTION_LogReg_Model2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Last check to make sure all fiction_small is in FinalOutput\n",
    "import pandas as pd\n",
    "fsmall = pd.read_csv('./Fiction_Small.csv')['Filename'].tolist()\n",
    "output = pd.read_csv('./FINAL_FICTION_LogReg_Model2.csv')['Filename'].tolist()\n",
    "print set(fsmall).issubset(set(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking which ECCO-Categories do these fiction files belong to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000200100.xml', '0000200200.xml', '0000200400.xml', '0000200500.xml']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>ESTC_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Vol_Number</th>\n",
       "      <th>Author</th>\n",
       "      <th>Imprint</th>\n",
       "      <th>Field_Headings</th>\n",
       "      <th>fn_no</th>\n",
       "      <th>nfn_no</th>\n",
       "      <th>ECCO_Category</th>\n",
       "      <th>ECCO_Collection</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031300100.xml</td>\n",
       "      <td>31300100</td>\n",
       "      <td>T021625</td>\n",
       "      <td>1736</td>\n",
       "      <td>Bibliotheca topographica Anglicana: or, a new ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Worrall, John</td>\n",
       "      <td>London : printed for J. Worrall at the Dove in...</td>\n",
       "      <td>Books, Prices, Catalogs, Booksellers', Great B...</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0031300200.xml</td>\n",
       "      <td>31300200</td>\n",
       "      <td>T013049</td>\n",
       "      <td>1787</td>\n",
       "      <td>A catalogue of books printed for, and sold by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dilly, Charles</td>\n",
       "      <td>[London], s.n, 1787.</td>\n",
       "      <td>Catalogs, Booksellers', Early works to 1800</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0031300300.xml</td>\n",
       "      <td>31300300</td>\n",
       "      <td>T057382</td>\n",
       "      <td>1800</td>\n",
       "      <td>Rules of a reading-society, established April ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anon</td>\n",
       "      <td>London : printed by H.D. Steel, No. 51, Lothbu...</td>\n",
       "      <td>[London Reading Society], Rules and practice, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0031300400.xml</td>\n",
       "      <td>31300400</td>\n",
       "      <td>T012488</td>\n",
       "      <td>1787</td>\n",
       "      <td>Rules for regulating the subscription library ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Anon</td>\n",
       "      <td>Stamford : printed by Newcomb and Peat, [1787].</td>\n",
       "      <td>[Stamford Subscription Library], Rules and pra...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>GenRef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0031300500.xml</td>\n",
       "      <td>31300500</td>\n",
       "      <td>W029739</td>\n",
       "      <td>1773</td>\n",
       "      <td>A catalogue of books, imported and to be sold ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Knox, Henry</td>\n",
       "      <td>[Boston : Sold by Henry Knox, 1773].</td>\n",
       "      <td>Booksellers and bookselling, Massachusetts, Bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>Manifest_GenRef</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>GenRef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filename  DocumentID  ESTC_ID  Date  \\\n",
       "0  0031300100.xml    31300100  T021625  1736   \n",
       "1  0031300200.xml    31300200  T013049  1787   \n",
       "2  0031300300.xml    31300300  T057382  1800   \n",
       "3  0031300400.xml    31300400  T012488  1787   \n",
       "4  0031300500.xml    31300500  W029739  1773   \n",
       "\n",
       "                                               Title Vol_Number  \\\n",
       "0  Bibliotheca topographica Anglicana: or, a new ...          0   \n",
       "1  A catalogue of books printed for, and sold by ...          0   \n",
       "2  Rules of a reading-society, established April ...          0   \n",
       "3  Rules for regulating the subscription library ...          0   \n",
       "4  A catalogue of books, imported and to be sold ...          0   \n",
       "\n",
       "           Author                                            Imprint  \\\n",
       "0   Worrall, John  London : printed for J. Worrall at the Dove in...   \n",
       "1  Dilly, Charles                               [London], s.n, 1787.   \n",
       "2            Anon  London : printed by H.D. Steel, No. 51, Lothbu...   \n",
       "3            Anon    Stamford : printed by Newcomb and Peat, [1787].   \n",
       "4     Knox, Henry               [Boston : Sold by Henry Knox, 1773].   \n",
       "\n",
       "                                      Field_Headings  fn_no  nfn_no  \\\n",
       "0  Books, Prices, Catalogs, Booksellers', Great B...      0      63   \n",
       "1        Catalogs, Booksellers', Early works to 1800      0      32   \n",
       "2  [London Reading Society], Rules and practice, ...      0       7   \n",
       "3  [Stamford Subscription Library], Rules and pra...      0      17   \n",
       "4  Booksellers and bookselling, Massachusetts, Bo...      0      39   \n",
       "\n",
       "     ECCO_Category ECCO_Collection Predicted_Class  \n",
       "0  Manifest_GenRef          ECCO_1          GenRef  \n",
       "1  Manifest_GenRef          ECCO_1          GenRef  \n",
       "2  Manifest_GenRef          ECCO_1          GenRef  \n",
       "3  Manifest_GenRef          ECCO_1          GenRef  \n",
       "4  Manifest_GenRef          ECCO_1          GenRef  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_table = pd.read_csv('/Users/sunyambagga/Desktop/ECCO Paper Writing/UPDATED_Table1_Combined_and_Annotated.csv')\n",
    "main_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>ESTC_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Vol_Number</th>\n",
       "      <th>Author</th>\n",
       "      <th>Imprint</th>\n",
       "      <th>Field_Headings</th>\n",
       "      <th>fn_no</th>\n",
       "      <th>nfn_no</th>\n",
       "      <th>ECCO_Category</th>\n",
       "      <th>ECCO_Collection</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4353</th>\n",
       "      <td>0003900900.xml</td>\n",
       "      <td>3900900</td>\n",
       "      <td>T110586</td>\n",
       "      <td>1753</td>\n",
       "      <td>Memoires secrets pour servir &lt;c3&gt;&lt;a0&gt; l'histoi...</td>\n",
       "      <td>0</td>\n",
       "      <td>M. M. C. F., Ecu&lt;c3&gt;&lt;a8&gt;ier</td>\n",
       "      <td>London : printed for R. Jennys, [1753?].</td>\n",
       "      <td>French fiction, 18th century</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Manifest_HistAndGeo</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>0004700401.xml</td>\n",
       "      <td>4700401</td>\n",
       "      <td>T125094</td>\n",
       "      <td>1748</td>\n",
       "      <td>Anecdotes de la cour de Fran&lt;c3&gt;&lt;a7&gt;ois I. Par...</td>\n",
       "      <td>Volume 1</td>\n",
       "      <td>Lussan, Marguerite de</td>\n",
       "      <td>Londres [i.e. Paris?] : chez Jean Nours [sic],...</td>\n",
       "      <td>France, Court and courtiers, France, History, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>Manifest_HistAndGeo</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>0004700402.xml</td>\n",
       "      <td>4700402</td>\n",
       "      <td>T125094</td>\n",
       "      <td>1748</td>\n",
       "      <td>Anecdotes de la cour de Fran&lt;c3&gt;&lt;a7&gt;ois I. Par...</td>\n",
       "      <td>Volume 2</td>\n",
       "      <td>Lussan, Marguerite de</td>\n",
       "      <td>Londres [i.e. Paris?] : chez Jean Nours [sic],...</td>\n",
       "      <td>France, Court and courtiers, France, History, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>343</td>\n",
       "      <td>Manifest_HistAndGeo</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>0004700403.xml</td>\n",
       "      <td>4700403</td>\n",
       "      <td>T125094</td>\n",
       "      <td>1748</td>\n",
       "      <td>Anecdotes de la cour de Fran&lt;c3&gt;&lt;a7&gt;ois I. Par...</td>\n",
       "      <td>Volume 3</td>\n",
       "      <td>Lussan, Marguerite de</td>\n",
       "      <td>Londres [i.e. Paris?] : chez Jean Nours [sic],...</td>\n",
       "      <td>France, Court and courtiers, France, History, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>Manifest_HistAndGeo</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>0007901400.xml</td>\n",
       "      <td>7901400</td>\n",
       "      <td>T069692</td>\n",
       "      <td>1782</td>\n",
       "      <td>The history of the civil wars in Germany, from...</td>\n",
       "      <td>0</td>\n",
       "      <td>Defoe, Daniel</td>\n",
       "      <td>Newark : printed by James Tomlinson, for the p...</td>\n",
       "      <td>Thirty Years' War, 1618-1648, Fiction, Great B...</td>\n",
       "      <td>2</td>\n",
       "      <td>379</td>\n",
       "      <td>Manifest_HistAndGeo</td>\n",
       "      <td>ECCO_1</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Filename  DocumentID  ESTC_ID  Date  \\\n",
       "4353  0003900900.xml     3900900  T110586  1753   \n",
       "4411  0004700401.xml     4700401  T125094  1748   \n",
       "4412  0004700402.xml     4700402  T125094  1748   \n",
       "4413  0004700403.xml     4700403  T125094  1748   \n",
       "4510  0007901400.xml     7901400  T069692  1782   \n",
       "\n",
       "                                                  Title Vol_Number  \\\n",
       "4353  Memoires secrets pour servir <c3><a0> l'histoi...          0   \n",
       "4411  Anecdotes de la cour de Fran<c3><a7>ois I. Par...   Volume 1   \n",
       "4412  Anecdotes de la cour de Fran<c3><a7>ois I. Par...   Volume 2   \n",
       "4413  Anecdotes de la cour de Fran<c3><a7>ois I. Par...   Volume 3   \n",
       "4510  The history of the civil wars in Germany, from...          0   \n",
       "\n",
       "                           Author  \\\n",
       "4353  M. M. C. F., Ecu<c3><a8>ier   \n",
       "4411        Lussan, Marguerite de   \n",
       "4412        Lussan, Marguerite de   \n",
       "4413        Lussan, Marguerite de   \n",
       "4510                Defoe, Daniel   \n",
       "\n",
       "                                                Imprint  \\\n",
       "4353           London : printed for R. Jennys, [1753?].   \n",
       "4411  Londres [i.e. Paris?] : chez Jean Nours [sic],...   \n",
       "4412  Londres [i.e. Paris?] : chez Jean Nours [sic],...   \n",
       "4413  Londres [i.e. Paris?] : chez Jean Nours [sic],...   \n",
       "4510  Newark : printed by James Tomlinson, for the p...   \n",
       "\n",
       "                                         Field_Headings  fn_no  nfn_no  \\\n",
       "4353                       French fiction, 18th century      0      30   \n",
       "4411  France, Court and courtiers, France, History, ...      0     304   \n",
       "4412  France, Court and courtiers, France, History, ...      1     343   \n",
       "4413  France, Court and courtiers, France, History, ...      0     309   \n",
       "4510  Thirty Years' War, 1618-1648, Fiction, Great B...      2     379   \n",
       "\n",
       "            ECCO_Category ECCO_Collection Predicted_Class  \n",
       "4353  Manifest_HistAndGeo          ECCO_1         Fiction  \n",
       "4411  Manifest_HistAndGeo          ECCO_1         Fiction  \n",
       "4412  Manifest_HistAndGeo          ECCO_1         Fiction  \n",
       "4413  Manifest_HistAndGeo          ECCO_1         Fiction  \n",
       "4510  Manifest_HistAndGeo          ECCO_1         Fiction  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fic_table = main_table.loc[main_table['Filename'].isin(output)]\n",
    "fic_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manifest_LitAndLang      7954\n",
       "Manifest_HistAndGeo       444\n",
       "Manifest_SSAndFineArt     100\n",
       "Manifest_RelandPhil        96\n",
       "Manifest_MedSciTech        11\n",
       "Manifest_Law                2\n",
       "Name: ECCO_Category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fic_table['ECCO_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8607"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7954+444+100+96+11+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files that are in fiction_small but not in final-fiction-fnames:  665\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sanity check: Investigating if all of fiction_small is present in FinalFiction.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "fnames_fiction_small = pd.read_csv('./Fiction_Small.csv')['Filename'].tolist()\n",
    "\n",
    "txt_fnames_fiction_small = [f + '.txt' for f in fnames_fiction_small]\n",
    "\n",
    "count = 0\n",
    "notinfinal_butinsmall = []\n",
    "for fn in txt_fnames_fiction_small:\n",
    "    if fn not in finalfiction_fnames:\n",
    "        count += 1\n",
    "        notinfinal_butinsmall.append(fn)\n",
    "\n",
    "print \"Files that are in fiction_small but not in final-fiction-fnames: \", count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiction small:  4558\n",
      "Intersection:  3893\n",
      "Not in fiction_big:  665\n"
     ]
    }
   ],
   "source": [
    "# That is interesting, because there were exactly 665 files that were not in fiction_big. \n",
    "# If these are the same, that means the classifier predicted all fiction_small accurately.\n",
    "\n",
    "small_and_big_intersection = fiction_big.loc[fiction_big['Filename'].isin(fnames_fiction_small)]\n",
    "intersection_fnames = small_and_big_intersection['Filename'].tolist()\n",
    "print \"Fiction small: \", len(fnames_fiction_small)\n",
    "print \"Intersection: \", len(intersection_fnames)\n",
    "\n",
    "notInBig = set(fnames_fiction_small) - set(intersection_fnames)\n",
    "print \"Not in fiction_big: \", len(notInBig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming if they are the same:\n",
    "txt_notInBig = [s + '.txt' for s in notInBig]\n",
    "set(txt_notInBig) == set(notinfinal_butinsmall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
