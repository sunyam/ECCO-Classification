{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_load(n):\n",
    "    with open('./features/Model3_all_stopwords_and_noPunc6/fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        fic = pickle.load(f)\n",
    "\n",
    "    with open('./features/Model3_all_stopwords_and_noPunc6/non_fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        nonfic = pickle.load(f)\n",
    "\n",
    "    return fic, nonfic\n",
    "\n",
    "fic50, nonfic50     = pickle_load(50)\n",
    "fic100, nonfic100   = pickle_load(100)\n",
    "fic500, nonfic500   = pickle_load(500)\n",
    "fic1000, nonfic1000 = pickle_load(1000)\n",
    "fic3000, nonfic3000 = pickle_load(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Different hyper-parameters in SVM.\n",
    "'''\n",
    "def my_SVM(X):\n",
    "    # Getting labels ready: 1 is for Fiction, 0 is for NonFiction\n",
    "    labels = [1]*4558 + [0]*4558\n",
    "    \n",
    "    tuned_parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']}, \n",
    "                        {'C': [1, 10, 100, 1000], 'gamma': ['auto', 0.001, 0.0001], 'kernel': ['rbf']}]\n",
    "\n",
    "#     tuned_parameters = [{'C': [10, 1000], 'gamma': ['auto', 0.001], 'kernel': ['rbf']}]\n",
    "    \n",
    "    metrics = ['f1']\n",
    "    m = ['precision', 'f1', 'accuracy', 'recall']\n",
    "    \n",
    "    # List of 4 dictionaries, where each dictionary represents all the results for that particular best model.\n",
    "    models = []\n",
    "    \n",
    "    for score in metrics:\n",
    "        model = {}\n",
    "        svc = SVC()\n",
    "        print \"Running for \", score\n",
    "        clf = GridSearchCV(svc, tuned_parameters, cv=10, scoring=score, verbose=2)\n",
    "        clf.fit(X, labels)\n",
    "        print \"\\nBest parameters for \" + score + \": \" + str(clf.best_estimator_)\n",
    "        print \"Best score achieved for \" + score + \": \" + str(clf.best_score_)\n",
    "        best_svc = clf.best_estimator_\n",
    "        # Now that I have the best parameters for each metric, running SVM for those specific parameters to obtain \n",
    "        # all values.\n",
    "        for s in m:\n",
    "            print \"Running the best \" + score + \" model for \" + s + \"..\"\n",
    "            model[s] = np.array(cross_val_score(best_svc, X, labels, cv=10, scoring=s))\n",
    "        \n",
    "        print \"For \", score \n",
    "        print model\n",
    "        print \"\\n\\n\"\n",
    "        models.append(model)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "'''\n",
    "For 50:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction50 = []\n",
    "countvec_nonfiction50 = []\n",
    "\n",
    "for doc in fic50:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction50.append(temp)\n",
    "    \n",
    "for doc in nonfic50:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction50.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction50 = countvec_fiction50 + countvec_nonfiction50\n",
    "    \n",
    "vectorizer50 = CountVectorizer()\n",
    "X50 = vectorizer50.fit_transform(fiction_plus_nonfiction50)\n",
    "\n",
    "results_50 = my_SVM(X50)\n",
    "print \"Done for 50\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "'''\n",
    "For 100:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction100 = []\n",
    "countvec_nonfiction100 = []\n",
    "\n",
    "for doc in fic100:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction100.append(temp)\n",
    "    \n",
    "for doc in nonfic100:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction100.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction100 = countvec_fiction100 + countvec_nonfiction100\n",
    "    \n",
    "vectorizer100 = CountVectorizer()\n",
    "X100 = vectorizer100.fit_transform(fiction_plus_nonfiction100)\n",
    "\n",
    "results_100 = my_SVM(X100)\n",
    "print \"Done for 100\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "\n",
    "'''\n",
    "For 500:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction500 = []\n",
    "countvec_nonfiction500 = []\n",
    "\n",
    "for doc in fic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction500.append(temp)\n",
    "    \n",
    "for doc in nonfic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction500.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction500 = countvec_fiction500 + countvec_nonfiction500\n",
    "    \n",
    "vectorizer500 = CountVectorizer()\n",
    "X500 = vectorizer500.fit_transform(fiction_plus_nonfiction500)\n",
    "\n",
    "results_500 = my_SVM(X500)\n",
    "print \"Done for 500\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 1000:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction1000 = []\n",
    "countvec_nonfiction1000 = []\n",
    "\n",
    "for doc in fic1000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction1000.append(temp)\n",
    "    \n",
    "for doc in nonfic1000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction1000.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction1000 = countvec_fiction1000 + countvec_nonfiction1000\n",
    "    \n",
    "vectorizer1000 = CountVectorizer()\n",
    "X1000 = vectorizer1000.fit_transform(fiction_plus_nonfiction1000)\n",
    "\n",
    "results_1000 = my_SVM(X1000)\n",
    "print \"Done for 1000\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 3000:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction3000 = []\n",
    "countvec_nonfiction3000 = []\n",
    "\n",
    "for doc in fic3000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction3000.append(temp)\n",
    "    \n",
    "for doc in nonfic3000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction3000.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction3000 = countvec_fiction3000 + countvec_nonfiction3000\n",
    "    \n",
    "vectorizer3000 = CountVectorizer()\n",
    "X3000 = vectorizer3000.fit_transform(fiction_plus_nonfiction3000)\n",
    "\n",
    "results_3000 = my_SVM(X3000)\n",
    "print \"Done for 3000\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "# Started running at 2:02PM (for 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'precision': array([ 0.94266055,  0.95680346,  0.9596603 ,  0.94129979,  0.97772829,\n",
       "          0.96      ,  0.95545657,  0.94849785,  0.95862069,  0.95273632])},\n",
       " {'f1': array([ 0.92152466,  0.9640914 ,  0.97518878,  0.9624866 ,  0.97016575,\n",
       "          0.95364238,  0.9480663 ,  0.95878525,  0.93707865,  0.89381564])},\n",
       " {'accuracy': array([ 0.92324561,  0.96381579,  0.9747807 ,  0.96162281,  0.97039474,\n",
       "          0.95394737,  0.94846491,  0.95833333,  0.93846154,  0.9       ])},\n",
       " {'recall': array([ 0.90131579,  0.97149123,  0.99122807,  0.98464912,  0.9627193 ,\n",
       "          0.94736842,  0.94078947,  0.96929825,  0.91648352,  0.84175824])}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results for 50:\n",
    "'''\n",
    "precision: Best parameters:  SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "Best score achieved for:  0.973527758605\n",
    "\n",
    "\n",
    "f1: Best parameters:  SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "Best score achieved for:  0.955059109236\n",
    "\n",
    "\n",
    "accuracy: Best parameters:  SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "Best score achieved for:  0.956450197455\n",
    "\n",
    "\n",
    "recall: Best parameters:  SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "Best score achieved for:  0.945809565599\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
