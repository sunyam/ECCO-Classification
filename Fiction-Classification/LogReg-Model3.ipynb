{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_load(n):\n",
    "    with open('./features/Model3_all_stopwords_and_noPunc6/fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        fic = pickle.load(f)\n",
    "\n",
    "    with open('./features/Model3_all_stopwords_and_noPunc6/non_fiction_' + str(n) + '.pickle', 'rb') as f:\n",
    "        nonfic = pickle.load(f)\n",
    "\n",
    "    return fic, nonfic\n",
    "\n",
    "fic50, nonfic50     = pickle_load(50)\n",
    "fic100, nonfic100   = pickle_load(100)\n",
    "fic500, nonfic500   = pickle_load(500)\n",
    "fic1000, nonfic1000 = pickle_load(1000)\n",
    "fic3000, nonfic3000 = pickle_load(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Different hyper-parameters in Logistic Regression.\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def my_LogReg(X):\n",
    "    # Getting labels ready: 1 is for Fiction, 0 is for NonFiction\n",
    "    labels = [1]*4558 + [0]*4558\n",
    "    \n",
    "    tuned_parameters = [{'C': [1, 10, 100, 1000], 'penalty': ['l1'], 'solver': ['liblinear']}, \n",
    "                        {'C': [1, 10, 100, 1000], 'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'sag']}]\n",
    "    metrics = ['f1']\n",
    "    m = ['precision', 'f1', 'accuracy', 'recall']\n",
    "    \n",
    "    # List of 4 dictionaries, where each dictionary represents all the results for that particular best model.\n",
    "    models = []\n",
    "    \n",
    "    for score in metrics:\n",
    "        model = {}\n",
    "        lr = LogisticRegression()\n",
    "        print \"Running for \", score\n",
    "        clf = GridSearchCV(lr, tuned_parameters, cv=10, scoring=score, verbose=1)\n",
    "        clf.fit(X, labels)\n",
    "        print \"\\nBest parameters for \" + score + \": \" + str(clf.best_estimator_)\n",
    "        print \"Best score achieved for \" + score + \": \" + str(clf.best_score_)\n",
    "        best_lr = clf.best_estimator_\n",
    "        \n",
    "        for s in m:\n",
    "            print \"Running the best \" + score + \" model for \" + s + \"..\"\n",
    "            model[s] = np.array(cross_val_score(best_lr, X, labels, cv=10, scoring=s))\n",
    "        \n",
    "        print \"For \", score \n",
    "        print model\n",
    "        print \"\\n\\n\"\n",
    "        models.append(model)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.954615263914\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.90131579,  0.98026316,  0.98903509,  0.98903509,  0.95833333,\n",
      "        0.95833333,  0.94298246,  0.97149123,  0.91428571,  0.85714286]), 'f1': array([ 0.92671928,  0.97491821,  0.9772481 ,  0.97198276,  0.96788483,\n",
      "        0.96574586,  0.95343681,  0.96199783,  0.94117647,  0.90277778]), 'precision': array([ 0.95359629,  0.96963124,  0.96573876,  0.95753715,  0.97762864,\n",
      "        0.97327394,  0.96412556,  0.95268817,  0.96969697,  0.95354523]), 'accuracy': array([ 0.92872807,  0.9747807 ,  0.97587719,  0.97258772,  0.96929825,\n",
      "        0.96600877,  0.95394737,  0.96162281,  0.94285714,  0.90769231])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 50\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n",
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.958756830053\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.90570175,  0.98684211,  0.98245614,  0.99342105,  0.95394737,\n",
      "        0.96052632,  0.96052632,  0.97149123,  0.94285714,  0.86593407]), 'f1': array([ 0.92429379,  0.97932535,  0.96864865,  0.97734628,  0.96141125,\n",
      "        0.96444444,  0.96035242,  0.96641387,  0.95690608,  0.911188  ]), 'precision': array([ 0.9516129 ,  0.96982759,  0.96760259,  0.96375267,  0.97321429,\n",
      "        0.96888889,  0.94989107,  0.95896328,  0.97291196,  0.95365854]), 'accuracy': array([ 0.93311404,  0.97916667,  0.97368421,  0.97807018,  0.96052632,\n",
      "        0.96052632,  0.9627193 ,  0.96600877,  0.95604396,  0.91098901])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 100\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n",
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.966254139344\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.9122807 ,  0.99561404,  0.99122807,  0.99780702,  0.95175439,\n",
      "        0.95833333,  0.95614035,  0.98245614,  0.92527473,  0.87032967]), 'f1': array([ 0.94117647,  0.99343545,  0.98367791,  0.9912854 ,  0.96551724,\n",
      "        0.9700333 ,  0.96888889,  0.98030635,  0.95141243,  0.91666667]), 'precision': array([ 0.97196262,  0.99126638,  0.9762419 ,  0.98484848,  0.97968397,\n",
      "        0.98202247,  0.98198198,  0.97816594,  0.97906977,  0.96821516]), 'accuracy': array([ 0.94298246,  0.99342105,  0.98355263,  0.99122807,  0.96600877,\n",
      "        0.97039474,  0.96929825,  0.98026316,  0.95274725,  0.92087912])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 500\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n",
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 36.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.966219498532\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.91447368,  0.99122807,  0.99122807,  0.99561404,  0.95175439,\n",
      "        0.96710526,  0.95175439,  0.96929825,  0.93406593,  0.87252747]), 'f1': array([ 0.94438138,  0.98905908,  0.98689956,  0.98695652,  0.96774194,\n",
      "        0.97130243,  0.96337403,  0.9724366 ,  0.95388076,  0.91772885]), 'precision': array([ 0.97892272,  0.98689956,  0.98264642,  0.97844828,  0.98642534,\n",
      "        0.97560976,  0.9752809 ,  0.97782705,  0.97921478,  0.97066015]), 'accuracy': array([ 0.94736842,  0.98903509,  0.98684211,  0.98684211,  0.96820175,\n",
      "        0.97149123,  0.96381579,  0.9747807 ,  0.95824176,  0.92197802])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 1000\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n",
      "Running for  f1\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 249.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for f1: LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score achieved for f1: 0.96509966521\n",
      "Running the best f1 model for precision..\n",
      "Running the best f1 model for f1..\n",
      "Running the best f1 model for accuracy..\n",
      "Running the best f1 model for recall..\n",
      "For  f1\n",
      "{'recall': array([ 0.91666667,  0.99780702,  0.99342105,  0.99780702,  0.95175439,\n",
      "        0.96052632,  0.94736842,  0.97368421,  0.92087912,  0.86373626]), 'f1': array([ 0.94689266,  0.99236641,  0.98908297,  0.99020675,  0.96774194,\n",
      "        0.96902655,  0.96098105,  0.97261774,  0.94892168,  0.91077636]), 'precision': array([ 0.97663551,  0.98698482,  0.98264642,  0.98272138,  0.98198198,\n",
      "        0.97767857,  0.97732426,  0.96943231,  0.98126464,  0.96332518]), 'accuracy': array([ 0.94627193,  0.99232456,  0.98903509,  0.99013158,  0.96820175,\n",
      "        0.96929825,  0.9627193 ,  0.97258772,  0.95054945,  0.91648352])}\n",
      "\n",
      "\n",
      "\n",
      "Done for 3000\n",
      "\n",
      "######################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "'''\n",
    "For 50:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction50 = []\n",
    "countvec_nonfiction50 = []\n",
    "\n",
    "for doc in fic50:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction50.append(temp)\n",
    "    \n",
    "for doc in nonfic50:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction50.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction50 = countvec_fiction50 + countvec_nonfiction50\n",
    "    \n",
    "vectorizer50 = CountVectorizer()\n",
    "X50 = vectorizer50.fit_transform(fiction_plus_nonfiction50)\n",
    "\n",
    "results_50 = my_LogReg(X50)\n",
    "print \"Done for 50\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 100:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction100 = []\n",
    "countvec_nonfiction100 = []\n",
    "\n",
    "for doc in fic100:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction100.append(temp)\n",
    "    \n",
    "for doc in nonfic100:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction100.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction100 = countvec_fiction100 + countvec_nonfiction100\n",
    "    \n",
    "vectorizer100 = CountVectorizer()\n",
    "X100 = vectorizer100.fit_transform(fiction_plus_nonfiction100)\n",
    "\n",
    "results_100 = my_LogReg(X100)\n",
    "print \"Done for 100\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "\n",
    "'''\n",
    "For 500:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction500 = []\n",
    "countvec_nonfiction500 = []\n",
    "\n",
    "for doc in fic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction500.append(temp)\n",
    "    \n",
    "for doc in nonfic500:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction500.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction500 = countvec_fiction500 + countvec_nonfiction500\n",
    "    \n",
    "vectorizer500 = CountVectorizer()\n",
    "X500 = vectorizer500.fit_transform(fiction_plus_nonfiction500)\n",
    "\n",
    "results_500 = my_LogReg(X500)\n",
    "print \"Done for 500\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 1000:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction1000 = []\n",
    "countvec_nonfiction1000 = []\n",
    "\n",
    "for doc in fic1000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction1000.append(temp)\n",
    "    \n",
    "for doc in nonfic1000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction1000.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction1000 = countvec_fiction1000 + countvec_nonfiction1000\n",
    "    \n",
    "vectorizer1000 = CountVectorizer()\n",
    "X1000 = vectorizer1000.fit_transform(fiction_plus_nonfiction1000)\n",
    "\n",
    "results_1000 = my_LogReg(X1000)\n",
    "print \"Done for 1000\\n\"\n",
    "print \"######################################################\\n\\n\"\n",
    "\n",
    "'''\n",
    "For 3000:\n",
    "'''\n",
    "# Getting it ready for Count Vectorizer:\n",
    "countvec_fiction3000 = []\n",
    "countvec_nonfiction3000 = []\n",
    "\n",
    "for doc in fic3000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_fiction3000.append(temp)\n",
    "    \n",
    "for doc in nonfic3000:\n",
    "    temp = ' '.join(doc)\n",
    "    countvec_nonfiction3000.append(temp)\n",
    "    \n",
    "fiction_plus_nonfiction3000 = countvec_fiction3000 + countvec_nonfiction3000\n",
    "    \n",
    "vectorizer3000 = CountVectorizer()\n",
    "X3000 = vectorizer3000.fit_transform(fiction_plus_nonfiction3000)\n",
    "\n",
    "results_3000 = my_LogReg(X3000)\n",
    "print \"Done for 3000\\n\"\n",
    "print \"######################################################\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
